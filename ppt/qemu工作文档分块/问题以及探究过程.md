# 问题探究过程

[toc]



## 实现指令翻译和捕捉

阅读intel手册，得到各个指令的二进制编码：

| 指令名称 | 二进制形式      |
| -------- | --------------- |
| UIRET    | 0xf3 0f 01 ec   |
| TESTUI   | 0xf3 0f 01 ed   |
| STUI     | 0xf3 0f 01 ef   |
| SENDUIPI | 0xf3 0f c7 /reg |
| CLUI     | 0xf3 0f 01 ee   |

找到x86指令翻译相关的代码：

```c
//target/i386/tcg/translate.c
//经过寻找,注意到f3是前缀标志位(4580行):
 /* Collect prefixes.  */ 
    switch (b) {
    case 0xf3:
        f3flag = true;  // 识别前缀,跳转到 4717行
        prefixes |= PREFIX_REPZ;
        goto next_byte;
//0f又会进行分支的再次跳转
reswitch:
    switch(b) {
    case 0x0f:
        /**************************/
        /* extended op code */
        b = x86_ldub_code(env, s) | 0x100;
        goto reswitch;

        /**************************/
        /* arith & logic */
        
//最后在相应分支下设置对应的指令捕捉代码
case 0x101:
        modrm = x86_ldub_code(env, s);
        switch (modrm) {
        case 0xee: /* rdpkru */
            if(prefixes & PREFIX_REPZ){
                printf("qemu:caught 0xf30fee CLUI\n");
                f3flag = false;
                break;
            }
            if (prefixes & PREFIX_LOCK) {
                goto illegal_op;
            }
            tcg_gen_trunc_tl_i32(s->tmp2_i32, cpu_regs[R_ECX]);
            gen_helper_rdpkru(s->tmp1_i64, cpu_env, s->tmp2_i32);
            tcg_gen_extr_i64_tl(cpu_regs[R_EAX], cpu_regs[R_EDX], s->tmp1_i64);
            break;
        case 0xec:
            if (prefixes & PREFIX_REPZ){
                printf("qemu:caught 0xf30f01ec UIRET\n");
                f3flag = false;
            }
            break;
        case 0xed:
            if (prefixes & PREFIX_REPZ){
                printf("qemu:caught 0xf30f01ed TESTUI\n");
                f3flag = false;
            }
            break;
        case 0xef: /* wrpkru */
            if(prefixes & PREFIX_REPZ){
                printf("qemu:caught 0xf30f01ef STUI\n");
                f3flag = false;
                break;
            }
            if (prefixes & PREFIX_LOCK) {
                goto illegal_op;
            }
            tcg_gen_concat_tl_i64(s->tmp1_i64, cpu_regs[R_EAX],
                                  cpu_regs[R_EDX]);
            tcg_gen_trunc_tl_i32(s->tmp2_i32, cpu_regs[R_ECX]);
            gen_helper_wrpkru(cpu_env, s->tmp2_i32, s->tmp1_i64);
            break;
        }
case 0x1c7: /* cmpxchg8b */
        if(prefixes & PREFIX_REPZ){
            printf("qemu: caught 0xf30fc7 SENDUIPI\n");
            modrm = x86_ldub_code(env, s); // 此句加上以解决illegal instruction的问题
            break;
        }
```



## 新的硬件状态设定

### 定位cpu状态

### cpu状态设定

```c++
//target/i386/cpu.h    CPUX86State
400行左右,msr编号定义
//target/i386/cpu.h/CPUArchState  1476 寄存器定义
```

#### 尝试寻找msr的读与写函数的位置

```c++
//target/i386/tcg/sysemu/misc_helper.c/helper_rdmsr 313
//target/i386/tcg/sysemu/misc_helper.c/helper_wrmsr 142
```

#### 增加对应的msr定义以及读写函数内容:

```c
//target/i386/cpu.h 258
#define CR4_UINTR_MASK (1U<<25)  // 软件使能控制位


//target/i386/cpu.h   404  mydefines msr 定义
#define MSR_IA32_UINTR_RR               0x985
#define MSR_IA32_UINTR_HANDLER          0x986
#define MSR_IA32_UINTR_STACKADJUST      0x987
#define MSR_IA32_UINTR_MISC             0x988
#define MSR_IA32_UINTR_PD               0x989
#define MSR_IA32_UINTR_TT               0x98a

// target/i386/cpu.h  CPUArchState 1565
uint64_t uintr_rr;
uint64_t uintr_handler;
uint64_t uintr_stackadjust;
uint64_t uintr_misc;
uint64_t uintr_pd;
uint64_t uintr_tt;
//target/i386/tcg/sysemu/misc_helper.c/helper_rdmsr 403
在文件头添加
#include "exec/log.h"
    case MSR_IA32_UINTR_RR:
        val = env->uintr_rr;
        if(Debug)qemu_log("qemu:rdmsr RR 0x%016lx\n",val);
        break;
    case MSR_IA32_UINTR_HANDLER:
        val = env->uintr_handler;
        qemu_log("qemu:rdmsr handler 0x%016lx\n",val);
        break;
    case MSR_IA32_UINTR_STACKADJUST:
        val = env->uintr_stackadjust;
        qemu_log("qemu:rdmsr stackadjust 0x%016lx\n",val);
        break;
    case MSR_IA32_UINTR_MISC:
        val = env->uintr_misc;
        qemu_log("qemu:rdmsr misc 0x%016lx eip: 0x%016lx\n",val,env->eip);
        break;
    case MSR_IA32_UINTR_PD:
        val = env->uintr_pd;
        qemu_log("qemu:rdmsr pd 0x%016lx\n",val);
        break;
    case MSR_IA32_UINTR_TT:
        val = env->uintr_tt;
        qemu_log("qemu:rdmsr tt 0x%016lx\n",val);
        break;
//target/i386/tcg/sysemu/misc_helper.c/helper_wrmsr   229
    case MSR_IA32_UINTR_RR:
        qemu_log("qemu:wrmsr RR 0x%lx\n",val);
        env->uintr_rr = val;
        if(val!= 0){ // 这里在后续实现逻辑时才添加
            if(Debug)qemu_log("getting rr not zero get into helper rr:%ld\n",val);
            helper_rrnzero(env);
        }
        break;
    case MSR_IA32_UINTR_HANDLER:
        qemu_log("qemu:wrmsr handler 0x%016lx\n",val);
        env->uintr_handler = val;
        break;
    case MSR_IA32_UINTR_STACKADJUST:
        qemu_log("qemu:wrmsr stackadjust 0x%lx\n",val);
        env->uintr_stackadjust = val;
        break;
    case MSR_IA32_UINTR_MISC:
        qemu_log("qemu:wrmsr misc 0x%016lx\n",val);
        env->uintr_misc = val;
        break;
    case MSR_IA32_UINTR_PD:
        qemu_log("qemu:wrmsr pd 0x%016lx\n",val);
        env->uintr_pd = val;
        break;
    case MSR_IA32_UINTR_TT:
        qemu_log("qemu:wrmsr tt 0x%016lx\n",val);
        env->uintr_tt = val;
        break;
```

### 指令模拟

研究一个具体的函数:

```c
gen_helper_rdtsc(cpu_env);  //target/i386/tcg/translate.c  7304
void helper_rdtsc(CPUX86State *env)  //target/i386/tcg/misc_helper.c  64
{
    helper_rdtsc(env);
    env->regs[R_ECX] = (uint32_t)(env->tsc_aux);
}
```

课件一个函数的helper函数的实现和调用关系符合以上的范式。

#### 尝试仿照验证函数定义和调用

```c
//target/i386/tcg/translate.c 5402 添加如下函数调用
gen_helper_senduipi(cpu_env, tcg_const_i32(uipi_index));
//target/i386/helper.h 35 添加如下宏定义
DEF_HELPER_2(senduipi, void ,env ,int)
//target/i386/tcg/misc_helper.c
void helper_senduipi(CPUX86State *env ,int uipi_index){
    if(Debug)printf("qemu:helper senduipi called receive %d index\n",uipi_index);
}
```

在打通后续的流程之后, 该函数确实可以被正确调用。



## 注意到定义新的硬件特性没有被识别

### 硬件向操作系统反馈feature

```shell
#arch/x86/kernel/uintr_fd.c/SYSCALL_DEFINE2(uintr_register_handler... 126
#修改部分 uintr 相关内核代码后，可以捕捉到对应的syscall确实被调用了，编译出的kernel输出如下：
[    6.608152] uintr_register_handler called
regeister returned 233
caught 0xf30fef STUI
create fd returned -1
Receiver enabled interrupts
Sender register error
```

```c
//以上对应的用户态代码如下(只放一部分)
int ret1 = uintr_register_handler(uintr_handler, 0);
	printf("regeister returned %d\n",ret1);
	ret = uintr_create_fd(0, 0);
	printf("create fd returned %d\n",ret);
	uintr_fd = ret;
	_stui();
	printf("Receiver enabled interrupts\n");
	if (pthread_create(&pt, NULL, &sender_thread, NULL)) {
		printf("Error creating sender thread\n");
		exit(EXIT_FAILURE);
	}
	/* Do some other work */
	while (!uintr_received)usleep(1);
	pthread_join(pt, NULL);
	close(uintr_fd);
	uintr_unregister_handler(0);
	printf("Success\n");
	exit(EXIT_SUCCESS);

//内核代码如下:
SYSCALL_DEFINE2(uintr_register_handler, u64 __user *, handler, unsigned int, flags)
{	
	if (Debug) printk("uintr_register_handler called\n");
	int ret;
	if (!uintr_arch_enabled())return 233;
		// return -EOPNOTSUPP;
	if (flags)return 234;
		// return -EINVAL;
	/* TODO: Validate the handler address */
	if (!handler) return 235;
		// return -EFAULT;
	ret = do_uintr_register_handler((u64)handler);
	pr_debug("recv: register handler task=%d flags %d handler %lx ret %d\n",
		 current->pid, flags, (unsigned long)handler, ret);
	return ret;
}
```

注意到返回的结果为233, 则查看对应的`uintr_arch_enabled`函数, 得到如下:

```c
inline bool uintr_arch_enabled(void){return static_cpu_has(X86_FEATURE_UINTR);}
```

发现无法再向下扩展函数, 查询`X86_FEATURE_UINTR`这个宏, 跳转到`arch/x86/include/asm/cpufeatures.h`其中存在大量的宏定义:

```c
#define X86_FEATURE_AVX512_4FMAPS	(18*32+ 3) /* AVX-512 Multiply Accumulation Single precision */
#define X86_FEATURE_FSRM		(18*32+ 4) /* Fast Short Rep Mov */
#define X86_FEATURE_UINTR		(18*32+ 5) /* User Interrupts support */
#define X86_FEATURE_AVX512_VP2INTERSECT (18*32+ 8) /* AVX-512 Intersect for D/Q */
#define X86_FEATURE_SRBDS_CTRL		(18*32+ 9) /* "" SRBDS mitigation MSR available */
```

经过和学长讨论, 尝试寻找和qemu之间的对应关系, 在qemu中尝试寻找`CPUID`相关的文件, 定位到`target/i386/cpu.h 600行左右`,有大量的定义。尝试寻找其中一个的对应关系`FPU`

```c
//qemu/target/i386/cpu.h  682
#define CPUID_EXT2_FPU     (1U << 0)
//linux/arch/x86/include/asm/cpufeatures.h  29
#define X86_FEATURE_FPU			( 0*32+ 0) /* Onboard FPU */
```

同时注意到, 这些feature有32为一组的分组特性, 尝试寻找uintr的对应关系, 并进行添加;

```c
//linux/arch/x86/include/asm/cpufeatures.h  380
#define X86_FEATURE_FSRM		(18*32+ 4) /* Fast Short Rep Mov */
#define X86_FEATURE_UINTR		(18*32+ 5) /* User Interrupts support */
//qemu/target/i386/cpu.h    860
/* Fast Short Rep Mov */
#define CPUID_7_0_EDX_FSRM              (1U << 4)
/* ？？？改cpuid uintr */
#define CPUID_7_0_EDX_UINTR              (1U << 5)
```

考虑到单纯定义未必会在qemu中体现, 可能需要有使用这个宏的地方, 开始继续寻找代码, 得到如下结果。

```c
//qemu/target/i386/cpu.c  4196
.features[FEAT_7_0_EDX] = CPUID_7_0_EDX_FSRM,
// 修改为
.features[FEAT_7_0_EDX] = CPUID_7_0_EDX_FSRM | CPUID_7_0_EDX_UINTR,
```

修改后编译qemu并执行，得到如下结果, 并无变化：

```shell
[  797.227827] uintr_register_handler called
regeister returned 233
create fd returned -1
Receiver enabled interrupts
Sender register error
```

为此在内核中测试FSRM是否是输出enable状态:

```c
// uintr内核代码	
if (!static_cpu_has(X86_FEATURE_FSRM)) {printk("FSRM not enabled\n");
}else{printk("FSRM enabled\n");}
if (!uintr_arch_enabled())return 233;
```

```shell
[    8.086769] uintr_register_handler called
[    8.087385] FSRM not enabled
regeister returned 233
caught 0xf30fef STUI
create fd returned -1
Receiver enabled interrupts
Sender register error
```

这说明qemu并没有未内核返回正确的信息位置，继续查看qemu代码，仔细阅读代码可知, 在cpu中列举了非常多的cpu芯片版本, 例如`EPYC-Milan`,`qemu64`,`phenom`等, 此处需要知道qemu具体编译出的cpu版本, 在对应的版本下添加cpu特性。

```shell
~/runlinux.sh > startlog.txt
grep CPU  startlog.txt # 得到以下关键信息
[    0.370356] smpboot: CPU0: AMD QEMU Virtual CPU version 2.5+ (family: 0xf, model: 0x6b, stepping: 0x1)
```

在`cpu.c`中搜索`QEMU Virtual CPU version`,定位到如下:

```c
.model_id = "QEMU Virtual CPU version " QEMU_HW_VERSION, //1802 对应 qemu64
.model_id = "QEMU Virtual CPU version " QEMU_HW_VERSION, //1931 对应 qemu32
.model_id = "QEMU Virtual CPU version " QEMU_HW_VERSION, //2057 对应 athlon
```

在`qemu64`中添加后，验证未成功， 在`athlon`中添也未验证成功。

```c
.features[FEAT_7_0_EDX] = CPUID_7_0_EDX_UINTR,
```

继续查看源代码

查看linux启动时的日志输出，主要关注linux启动前的部分, 可见是TCG出现了问题

```shell
xxy@7af409e42583:~/qemu/build$ run > ~/startlog.txt  #写入log,防止大面积刷屏
qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.07H:EDX.fsrm [bit 4]
qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.07H:EDX [bit 5]
qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.07H:EDX.fsrm [bit 4]
qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.07H:EDX [bit 5]
```

注释掉`cpu.c`中的下面这一句,再次查看输出

```c
.model_id = "QEMU Virtual CPU version " QEMU_HW_VERSION, //1802 对应 qemu64
//下面是shell命令
xxy@7af409e42583:~/qemu/build$ run > ~/startlog.txt  #写入log,防止大面积刷屏
```

没有相关输出, 说明cpu确实按照`qemu64`进行初始化, 接下来尝试寻找TCG支持相关的代码, 以及warning 发出的地方, 搜索`doesn't support requested feature`, 找到如下:

```c
//qemu/target/i386/cpu.c  6301
static void x86_cpu_filter_features(X86CPU *cpu, bool verbose)
if (verbose) {
        prefix = accel_uses_host_cpuid()
                 ? "host doesn't support requested feature"
                 : "TCG doesn't support requested feature？"; // 改
}
// 4347
static void mark_unavailable_features();
// 6153
void x86_cpu_expand_features(X86CPU *cpu, Error **errp);
```

通过插入输出,编译后再次执行得到如下结果:

```shell
qemu-system-x86_64: warning: expand featrue called
qemu-system-x86_64: warning: x86 cpu filter feature called
qemu-system-x86_64: warning: TCG doesn't support requested feature？: CPUID.07H:EDX.fsrm [bit 4]
qemu-system-x86_64: warning: TCG doesn't support requested feature？: CPUID.07H:EDX [bit 5]
qemu-system-x86_64: warning: expand featrue called
qemu-system-x86_64: warning: x86 cpu filter feature called
qemu-system-x86_64: warning: TCG doesn't support requested feature？: CPUID.07H:EDX.fsrm [bit 4]
qemu-system-x86_64: warning: TCG doesn't support requested feature？: CPUID.07H:EDX [bit 5]
```

再次寻找源代码，注意到如下函数：

```c
//qemu/target/i386/cpu.c  4989
uint64_t x86_cpu_get_supported_feature_word(FeatureWord w,
                                            bool migratable_only) // ？？？得到支持的featureword信息
FeatureWordInfo *wi = &feature_word_info[w];
uint64_t r = 0;
  if (kvm_enabled()) {
        if(Debug)warn_report("kvm enabled");
        switch (wi->type) {
        case CPUID_FEATURE_WORD:
///.....
        case MSR_FEATURE_WORD:
//.....
        }
    } else if (hvf_enabled()) {
        if(Debug)warn_report("hvf enabled");
//.......
    } else if (tcg_enabled()) {
  			if(Debug)warn_report("tcg enabled");
        r = wi->tcg_features;
    } else {
        return ~0;
    }
//进行输出定位后, 确认为r = wi->tcg_features; 这一行起主要作用,继续深入, 定位到一个巨大结构体中的位置
//qemu/target/i386/cpu.c  855
[FEAT_7_0_EDX] = {
        .type = CPUID_FEATURE_WORD,
        .feat_names = {
            NULL, NULL, "avx512-4vnniw", "avx512-4fmaps",
            "fsrm", "uintr", NULL, NULL,  // 改，加入feature info 信息
            "avx512-vp2intersect", NULL, "md-clear", NULL,
            NULL, NULL, "serialize", NULL,
            "tsx-ldtrk", NULL, NULL /* pconfig */, NULL,
            NULL, NULL, "amx-bf16", "avx512-fp16",
            "amx-tile", "amx-int8", "spec-ctrl", "stibp",
            NULL, "arch-capabilities", "core-capability", "ssbd",
        },
        .cpuid = {
            .eax = 7,
            .needs_ecx = true, .ecx = 0,
            .reg = R_EDX,
        },
        .tcg_features = TCG_7_0_EDX_FEATURES,  //这个宏,很关键
    },
// 进入展开的宏
//qemu/target/i386/cpu.c  666
#define TCG_7_0_EDX_FEATURES 0
// 修改后:
#define TCG_7_0_EDX_FEATURES (CPUID_7_0_EDX_UINTR)
```

#### 玄学问题:

以上操作完成后, linux依旧返回233, 但是在对linux做了以下理论上不会影响逻辑的修改后重新编译, 输出发生变化。

```c
//arch/x86/kernel/cpu/common.c  327
static __always_inline void setup_uintr(struct cpuinfo_x86 *c) // 初始化用户态中断,改？？？
{
	/* check the boot processor, plus compile options for UINTR. */
	if (!cpu_feature_enabled(X86_FEATURE_UINTR))
		printk("at setup uintr cpu featrue not enabled\n");
		goto disable_uintr;

	/* checks the current processor's cpuid bits: */
	if (!cpu_has(c, X86_FEATURE_UINTR))
		printk("at setup uintr cpu has not enabled\n");
		goto disable_uintr;

	/* Confirm XSAVE support for UINTR is present. */
	if (!cpu_has_xfeatures(XFEATURE_MASK_UINTR, NULL)) {
		printk("at setup uintr XSAVE not enabled\n");
		pr_info_once("x86: User Interrupts (UINTR) not enabled. XSAVE support for UINTR is missing.\n");
		goto clear_uintr_cap;
	}
```

```shell
# linux 内执行uipi_sample,输出如下:
/ # uipi_sample 
[    7.037078] uintr_register_handler called
[    7.038450] FSRM not enabled
wrmsr handler 
wrmsr pd 
wrmsr stackadjust 
rdmsr misc 
wrmsr misc 
# ..... rdmsr misc 若干
rdmsr misc 
regeister returned 0
rdmsr misc 
# ..... rdmsr misc 若干
create fd returned 3
rdmsr misc 
rdmsr misc 
rdmsr misc 
caught 0xf30fef STUI
rdmsr misc 
rdmsr misc 
Receiver enabled interrupts
rdmsr misc 
# ..... rdmsr misc 若干
wrmsr tt 
rdmsr misc 
rdmsr misc 
wrmsr misc 
rdmsr misc 
# ..... rdmsr misc 若干 
Sending IPI from sender thread
rdmsr misc 
# ..... rdmsr misc 若干 
[    7.085385] traps: uipi_sample[78] trap invalid opcode ip:401eb7 sp:7f44b1a09d90 error:0 in uipirdmsr misc 
_sample[401000+af000]
rdmsr misc 
# ..... rdmsr misc 若干
wrmsr misc 
wrmsr tt 
wrmsr pd 
wrmsr RR 
wrmsr stackadjust 
wrmsr handler 
[    7.112267] uipi_sample (77) used greatest stack depth: 14456 bytes left
rdmsr misc 
wrmsr misc 
wrmsr tt 
Illegal instruction
```

至此内核可以读取相关msr, 所以将内核代码修改的部分进行回调, 完善指令捕捉，完善信息输出，最后得到如下输入出: 

##### 值得思考

第一次执行：

```shell
/ # uipi_sample 
[    6.746036] uintr_register_handler called
qemu:wrmsr handler 0x0000000000401de5
qemu:wrmsr pd 0xffffa2ca438bc940
qemu:wrmsr stackadjust 0x0000000000000080
qemu:rdmsr misc 0x0000000000000000
qemu:wrmsr misc 0x000000ec00000000
[    6.747922] recv: register handler task=78 flags 0 handler 401de5 ret 0
qemu:rdmsr misc 0x000000ec00000000
#....
regeister returned 0qemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
#....
[    6.763195] uintr_create_fd called
[    6.765280] recv: Alloc vector success uintrfd 3 uvec 0 for task=78
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
create fd returned 3qemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
qemu:caught 0xf30f01ef STUI
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
Receiver enabled interruptsqemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
#.....
[    6.789114] uintr_register_sender called
qemu:wrmsr tt 0xffffa2ca418b0001
qemu:rdmsr misc 0x0000000000000000
qemu:wrmsr misc 0x0000000000000100
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
[    6.792473] send: register sender task=79 flags 0 ret(uipi_id)=0
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
Sending IPI from sender thread
qemu:rdmsr misc 0x000000ec00000000
qemu: caught 0xf30fc7 SENDUIPI
qemu:rdmsr misc 0x000000ec00000000
#.....
[    6.798139] traps: uipi_sample[79] trap invalid opcode ip:401eba sp:7ff7c490ed90 error:0 in uipi_sample[401000+af000]
qemu:rdmsr misc 0x000000ec00000000
#......
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
qemu:wrmsr pd 0x0000000000000000
qemu:wrmsr RR 0x0000000000000000
qemu:wrmsr stackadjust 0x0000000000000000
qemu:wrmsr handler 0x0000000000000000
[    6.813875] recv: Release uintrfd for r_task 78 uvec 0
qemu:rdmsr misc 0x0000000000000100
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
```

第二次执行：

```shell
/ # uipi_sample 
[   38.183970] uintr_register_handler called
qemu:wrmsr handler 0x0000000000401de5
qemu:wrmsr pd 0xffffa2ca438bc9c0
qemu:wrmsr stackadjust 0x0000000000000080
qemu:rdmsr misc 0x0000000000000000
qemu:wrmsr misc 0x000000ec00000000
[   38.184359] recv: register handler task=80 flags 0 handler 401de5 ret 0
qemu:rdmsr misc 0x000000ec00000000
#.....
regeister returned 0qemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
[   38.186027] uintr_create_fd called
[   38.186255] recv: Alloc vector success uintrfd 3 uvec 0 for task=80
qemu:rdmsr misc 0x000000ec00000000
create fd returned 3qemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
Receiver enabled interruptsqemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
#.....
[   38.190652] uintr_register_sender called
qemu:rdmsr misc 0x000000ec00000000
qemu:wrmsr tt 0xffffa2ca418b0001
qemu:rdmsr misc 0x0000000000000000
qemu:wrmsr misc 0x0000000000000100
[   38.191610] send: registeqemu:rdmsr misc 0x000000ec00000000
r sender task=81 flags 0 ret(uipi_id)=0
qemu:rdmsr misc 0x000000ec00000000
Sending IPI from sender thread
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
[   38.193956] traps: uipi_sample[81] trap invalid opcode ip:401eba sp:7f845374fd90 error:0 in uipi_sample[401000+af000]
qemu:rdmsr misc 0x000000ec00000000
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
qemu:wrmsr pd 0x0000000000000000
qemu:wrmsr RR 0x0000000000000000
qemu:wrmsr stackadjust 0x0000000000000000
qemu:wrmsr handler 0x0000000000000000
[   38.202607] recv: Release uintrfd for r_task 80 uvec 0
qemu:rdmsr misc 0x0000000000000100
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
Illegal instruction
```

注意到以上两者的区别，这个很奇怪。

注意到，在捕捉SENDUIPI时，没有将指令的最后一位，即最后一位寄存器表示的字节入读，导致后续出现非法指令报错，修改捕捉SENDUIPI的的代码如下。

```c
case 0x1c7: /* cmpxchg8b */
        if(prefixes & PREFIX_REPZ){
            printf("qemu: caught 0xf30fc7 SENDUIPI\n");
            modrm = x86_ldub_code(env, s); // 此句加上以解决illegal instruction的问题
            break;
        }
```

修改`uipi_sample.c`,使得最后不再死循环等待，随后的运行代码如下：

```shell
/ # uipi_sample 
[    9.059653] uintr_register_handler called
qemu:wrmsr handler 0x0000000000401de5
qemu:wrmsr pd 0xffff9fa5039233c0
qemu:wrmsr stackadjust 0x0000000000000080
qemu:rdmsr misc 0x0000000000000000
qemu:wrmsr misc 0x000000ec00000000
[    9.062016] recv: register handler task=78 flags 0 handler 401de5 ret 0
qemu:rdmsr misc 0x000000ec00000000
#......
regeister returned 0qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
#......
[    9.075342] uintr_create_fd called
[    9.077466] recv: Alloc vector success uintrfd 3 uvec 0 for task=78
qemu:rdmsr misc 0x000000ec00000000
create fd returned 3qemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000
#...
qemu:caught 0xf30f01ef STUI
qemu:rdmsr misc 0x000000ec00000000
Receiver enabled interruptsqemu:rdmsr misc 0x000000ec00000000
qemu:rdmsr misc 0x000000ec00000000

qemu:rdmsr misc 0x000000ec00000000
#....
[    9.097662]qemu:rdmsr misc 0x000000ec00000000
 uintr_register_sender called
qemu:wrmsr tt 0xffff9fa5018cf001
qemu:rdmsr misc 0x0000000000000000
qemu:wrmsr misc 0x0000000000000100
[    9.104338] send: register sender task=79 flags 0 ret(uipi_id)=0
Sending IPI from sender thread index:0 
qemu: caught 0xf30fc7 SENDUIPI
qemu:helper senduipi called receive  regidx:240, uipiindex: 0
[    9.106657] uintr_unregister_sender called
[    9.108545] send: unregister sender uintrfd 3 for task=79 ret 0
qemu:rdmsr misc 0x0000000000000100
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
qemu:rdmsr misc 0x000000ec00000000
#......
[    9.127159] recv: Release uintrfd for r_task 78 uvec 0
qemu:rdmsr misc 0x000000ec00000000
[    9.129770] uintr_unregister_handler called
qemu:rdmsr misc 0x000000ec00000000
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr pd 0x0000000000000000
qemu:wrmsr RR 0x0000000000000000
qemu:wrmsr stackadjust 0x0000000000000000
qemu:wrmsr handler 0x0000000000000000
[    9.132581] recv: unregister handler task=78 flags 0 ret 0
Success
```



## 实现内存读写

qemu中有大量的内存读写指令函数, 但是其具体的作用机制并不清晰, 查询的是物理地址还是虚拟地址也没有说明。在实现内存读写的过程中, 由于senduipi是在用户态执行的指令, 但是直接仿照其他指令访问内核维护的地址, 会触发异常。一个办法是提权, 另一个办法是硬件进行查页表, 经过多次的尝试, 我们最终找到了硬件查页表的方法, 并成功访问了对应的地址。

以下是一些失败的尝试:

```c
//失败的方法
void helper_senduipi(CPUX86State *env ,int reg_index){
    int uipi_index = env->regs[R_EAX];
    if(Debug)printf("qemu:helper senduipi called receive  regidx:%d, uipiindex: %d\n",reg_index,uipi_index);
    uint64_t content = cpu_ldq_data_ra(env, (env->uintr_tt>>3)<<3,0);
    if(Debug)printf("data of uitt0is 0x%016lx\n",content);
}
/* 操作系统报错
qemu:helper senduipi called receive  regidx:240, uipiindex: 0
 IPI from sender thread index:0 
[   29.290347] uipi_sample[79]: segfault at ffff9315c3951000 ip 0000000000401eb4 sp 00007f9cba791d90 error 5 in uipi_sample[401000+af000]
[   29.293130] Code: 89 c7 e8 ff 18 02 00 bf 01 00 00 00 e8 75 91 01 00 8b 45 f4 89 c6 48 8d 05 81 e1 0a 00 48 89 c7 b8 00 00 00 00 e8 1c 9c 01 00 <8b> 45 f4 48 98 48 89 45 f8 48 8b 45 f8 f3 0f c7 f0 90 8b 05 08 e5
qemu:wrmsr misc 0x0000000000000000
*/


TCGv t0;
t0 = tcg_temp_local_new();
t0 = (TCGv)env->uintr_tt; // 将t0修改为地址
if(Debug){printf("debug: before t0: %llx   A0: %llx\n",(long long unsigned)t0,(long long unsigned)s->A0);}
gen_op_ld_v(s, ot, t0, s->A0);
if(Debug){printf("debug: after  t0: %llx   A0: %llx\n",(long long unsigned)t0,(long long unsigned)s->A0);}
tcg_temp_free(t0);
/*
debug: before t0: ffff901883890001   A0: bf8
qemu-system-x86_64: /home/xxy/qemu/include/tcg/tcg.h:657: temp_idx: Assertion `n >= 0 && n < tcg_ctx->nb_temps' failed.
/home/xxy/runlinux.sh: line 5: 82338 Aborted                 (core dumped) /home/xxy/qemu/build/x86_64-softmmu/qemu-system-x86_64 

debug: before t0: ed0   A0: ffff8cf9838c0001
qemu-system-x86_64: /home/xxy/qemu/include/tcg/tcg.h:657: temp_idx: Assertion `n >= 0 && n < tcg_ctx->nb_temps' failed.
/home/xxy/runlinux.sh: line 5: 83796 Aborted  

*/


void helper_senduipi(CPUX86State *env ,int reg_index){
    CPUState *cs = env_cpu(env);
    int uipi_index = env->regs[R_EAX];
    if(Debug)printf("qemu:helper senduipi called receive  regidx:%d, uipiindex: %d\n",reg_index,uipi_index);
    uint64_t content = x86_ldq_phys(cs,(env->uintr_tt>>3)<<3);
    // uint64_t content = cpu_ldq_data_ra(env, (env->uintr_tt>>3)<<3,0);
    if(Debug)printf("data of uitt0is 0x%016lx\n",content);
}
读取了错误的数据
/*
qemu:helper senduipi called receive  regidx:240, uipiindex: 0
data of uitt0is 0x0000000000000000
*/
                 

其他的方法也都失败了
printf("qemu: caught 0xf30fc7 SENDUIPI\n "); // 改 Debug
uint64_t content;
cpu_physical_memory_rw(env->uintr_tt,&content,8,false);
if(Debug) printf("    xxx               %lx \n", content);

/*qemu: caught 0xf30fc7 SENDUIPI
                    0 
qemu:helper senduipi called receive  regidx:240, uipiindex: 0 */

cpu_ldq_mmuidx_ra(env, addr, mem_idx, GETPC()); 
// uint64_t content = x86_ldq_phys(cs,uitt_phyaddress + (uitte_index<<4));
// uint64_t upidaddress = x86_ldq_phys(cs, uitt_phyaddress + (uitte_index<<4) + 8);
```

正确的方法如下, 其中核心的方法是找到了并重写了用于将虚拟地址转换为物理地址的方法。得到物理地址后, `cpu_physical_memory_rw`函数可以正确地读写内存。

```c
//正确的方法：
    // read tempUITTE from 16 bytes at UITTADDR+ (reg « 4);
    uint64_t uitt_phyaddress = get_hphys2(cs, (env->uintr_tt>>3)<<3 , MMU_DATA_LOAD, &prot);
    if(Debug) printf("qemu: uitt_phyaddress %lx \n", uitt_phyaddress);
    struct uintr_uitt_entry uitte;
    cpu_physical_memory_rw(uitt_phyaddress + (uitte_index<<4), &uitte, 16,false);
    if(Debug)printf("qemu: data of uitt valid:%d user_vec:%d \n",uitte.valid, uitte.user_vec);
    if(Debug)printf("qemu: UPID address 0x%016lx\n", uitte.target_upid_addr);
    // read tempUPID from 16 bytes at tempUITTE.UPIDADDR;// under lock
    uint64_t upid_phyaddress = get_hphys2(cs, uitte.target_upid_addr, MMU_DATA_LOAD, &prot);
    struct uintr_upid upid;
    cpu_physical_memory_rw(upid_phyaddress, &upid, 16, false);
    if(Debug)printf("qemu: content of upid:  status:0x%x    nv:0x%x    ndst:0x%x    0x%016lx\n", upid.nc.status, upid.nc.nv, upid.nc.ndst, upid.puir);
    // tempUPID.PIR[tempUITTE.UV] := 1;
    upid.puir |= 1<<uitte.user_vec;
    //IF tempUPID.SN = tempUPID.ON = 0
    if(upid.nc.status == 0){
    //THEN  tempUPID.ON := 1;   sendNotify := 1;
        upid.nc.status |= UPID_ON;
    }else{ // ELSE sendNotify := 0;

    }
    //write tempUPID to 16 bytes at tempUITTE.UPIDADDR;// release lock
```

在逻辑实现方面, 如果不修改upid.puir, 得到如下输出

```shell
emu: caught 0xf30fc7 SENDUIPI
 qemu:helper senduipi called receive  regidx:240, uipiindex: 0
mmu_translate ret: -1
qemu: uitt_phyaddress 290d000 
qemu: data of uitt valid:1 user_vec:0 
qemu: UPID address 0xffff9e3682a11840
mmu_translate ret: -1
qemu: content of upid:  status:0x0    nv:0xec    ndst:0x100    0x0000000000000000
qemu: data write back in upid:  status:0x1    nv:0xec    ndst:0x100    0x0000000000000000
[    5.551340] uintr_unregister_sender called
[    5.552576] send: unregister sender uintrfd 3 for task=78 ret 0
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
Sending IPI from sender thread index:0 
[    5.563810] recv: Release uintrfd for r_task 77 uvec 0
[    5.567603] uintr_unregister_handler called
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr pd 0x0000000000000000
qemu:wrmsr RR 0x0
qemu:wrmsr stackadjust 0x0
qemu:wrmsr handler 0x0000000000000000
[    5.571613] recv: unregister handler task=77 flags 0 ret 0
Success
```

如果修改upid.puir, 则用户程序不会执行结束. 这和linux内核实现有关, 我们之后讨论:

```shell
ending IPI from sender thread index:0 
qemu: caught 0xf30fc7 SENDUIPI
 qemu:helper senduipi called receive  regidx:240, uipiindex: 0
mmu_translate ret: -1
qemu: uitt_phyaddress 2a3b000 
qemu: data of uitt valid:1 user_vec:0 
qemu: UPID address 0xffff9bfac293fd00
mmu_translate ret: -1
qemu: content of upid: status:0x0    nv:0xec    ndst:0x0    0x0000000000000000
qemu: data write back in upid:  status:0x1    nv:0xec    ndst:0x0    0x0000000000000001
[    9.319021] uintr_unregister_sender called
[    9.322055] send: unregister sender uintrfd 3 for task=79 ret 0
qemu:wrmsr misc 0x0000000000000000
qemu:wrmsr tt 0x0000000000000000
# 随后一直在读 rdmsr misc 0x000000ec00000000
```





## 中断的定位

### 找到中断逻辑部分,添加pins

```c
bool x86_cpu_exec_interrupt(CPUState *cs, int interrupt_request)  //???？？？中断相关，接收方了已经是
{
    X86CPU *cpu = X86_CPU(cs);
    CPUX86State *env = &cpu->env;
    int intno;

    interrupt_request = x86_cpu_pending_interrupt(cs, interrupt_request);
    if (!interrupt_request) {
        return false;
    }
    /* Don't process multiple interrupt requests in a single call.
     * This is required to make icount-driven execution deterministic.
     */
    switch (interrupt_request) {
    case CPU_INTERRUPT_POLL:
        cs->interrupt_request &= ~CPU_INTERRUPT_POLL;
        apic_poll_irq(cpu->apic_state);
        break;
    case CPU_INTERRUPT_SIPI:
        if(Debug) printf("x86 cpu exec interrupt called sipi \n");
        do_cpu_sipi(cpu);
        break;
    case CPU_INTERRUPT_SMI:
        cpu_svm_check_intercept_param(env, SVM_EXIT_SMI, 0, 0);
        cs->interrupt_request &= ~CPU_INTERRUPT_SMI;
        do_smm_enter(cpu);
        break;
    case CPU_INTERRUPT_NMI:
        cpu_svm_check_intercept_param(env, SVM_EXIT_NMI, 0, 0);
        cs->interrupt_request &= ~CPU_INTERRUPT_NMI;
        env->hflags2 |= HF2_NMI_MASK;
        do_interrupt_x86_hardirq(env, EXCP02_NMI, 1);
        break;
    case CPU_INTERRUPT_MCE:
        cs->interrupt_request &= ~CPU_INTERRUPT_MCE;
        do_interrupt_x86_hardirq(env, EXCP12_MCHK, 0);
        break;
    case CPU_INTERRUPT_HARD:
        
        cpu_svm_check_intercept_param(env, SVM_EXIT_INTR, 0, 0);
        cs->interrupt_request &= ~(CPU_INTERRUPT_HARD |
                                   CPU_INTERRUPT_VIRQ);
        intno = cpu_get_pic_interrupt(env);
        if(Debug )printf("!!! interrupt %d  intno:%d \n",interrupt_request, intno); //改 后面为了过滤,添加了  Debug && intno == 0xec
        qemu_log_mask(CPU_LOG_INT,
                      "Servicing hardware INT=0x%02x\n", intno);
        do_interrupt_x86_hardirq(env, intno, 1);
        break;
    case CPU_INTERRUPT_VIRQ:
        cpu_svm_check_intercept_param(env, SVM_EXIT_VINTR, 0, 0);
        intno = x86_ldl_phys(cs, env->vm_vmcb
                             + offsetof(struct vmcb, control.int_vector));
        qemu_log_mask(CPU_LOG_INT,
                      "Servicing virtual hardware INT=0x%02x\n", intno);
        do_interrupt_x86_hardirq(env, intno, 1);
        cs->interrupt_request &= ~CPU_INTERRUPT_VIRQ;
        env->int_ctl &= ~V_IRQ_MASK;
        break;
    }

    /* Ensure that no TB jump will be modified as the program flow was changed.  */
    return true;
}

void do_interrupt_all(X86CPU *cpu, int intno, int is_int,
                      int error_code, target_ulong next_eip, int is_hw) // 接收方执行中断？
{
    CPUX86State *env = &cpu->env;

    if (qemu_loglevel_mask(CPU_LOG_INT)) {
        if ((env->cr[0] & CR0_PE_MASK)) {
            static int count;

            qemu_log("%6d: v=%02x e=%04x i=%d cpl=%d IP=%04x:" TARGET_FMT_lx
                     " pc=" TARGET_FMT_lx " SP=%04x:" TARGET_FMT_lx,
                     count, intno, error_code, is_int,
                     env->hflags & HF_CPL_MASK,
                     env->segs[R_CS].selector, env->eip,
                     (int)env->segs[R_CS].base + env->eip,
                     env->segs[R_SS].selector, env->regs[R_ESP]);
            if (intno == 0x0e) {
                qemu_log(" CR2=" TARGET_FMT_lx, env->cr[2]);
            } else {
                qemu_log(" env->regs[R_EAX]=" TARGET_FMT_lx, env->regs[R_EAX]);
            }
            qemu_log("\n");
            log_cpu_state(CPU(cpu), CPU_DUMP_CCOP);
#if 0
            {
                int i;
                target_ulong ptr;

                qemu_log("       code=");
                ptr = env->segs[R_CS].base + env->eip;
                for (i = 0; i < 16; i++) {
                    qemu_log(" %02x", ldub(ptr + i));
                }
                qemu_log("\n");
            }
#endif
            count++;
        }
    }
    if (env->cr[0] & CR0_PE_MASK) { // 改， 中断具体分发，应该不涉及user only
#if !defined(CONFIG_USER_ONLY)
        if (env->hflags & HF_GUEST_MASK) {
            printf("HF_GUEST_MASK even \n");
            handle_even_inj(env, intno, is_int, error_code, is_hw, 0);
        }
#endif
#ifdef TARGET_X86_64
        if (env->hflags & HF_LMA_MASK) {
            printf("HF_LMA_MASK 64 \n");
            do_interrupt64(env, intno, is_int, error_code, next_eip, is_hw);
        } else
#endif
        {   
            printf("interrupt protected \n");
            do_interrupt_protected(env, intno, is_int, error_code, next_eip,
                                   is_hw);
        }
    } else {
#if !defined(CONFIG_USER_ONLY)
        if (env->hflags & HF_GUEST_MASK) {
            printf("HF_GUEST_MASK even inj \n");
            handle_even_inj(env, intno, is_int, error_code, is_hw, 1);
        }
#endif  
        printf("do real \n");
        do_interrupt_real(env, intno, is_int, error_code, next_eip);
    }

#if !defined(CONFIG_USER_ONLY)
    if (env->hflags & HF_GUEST_MASK) {
        printf("HF_GUEST_MASK do real \n");
        CPUState *cs = CPU(cpu);
        uint32_t event_inj = x86_ldl_phys(cs, env->vm_vmcb +
                                      offsetof(struct vmcb,
                                               control.event_inj));

        x86_stl_phys(cs,
                 env->vm_vmcb + offsetof(struct vmcb, control.event_inj),
                 event_inj & ~SVM_EVTINJ_VALID);
    }
#endif
}
```

```shell
#对应输出
qemu:rdmsr misc 0x000000ec00000000
!!! interrupt 2  intno:236 
HF_LMA_MASK 64 
!!! interrupt 2  intno:234 
HF_LMA_MASK 64 
[   37.623955] rdmsrl 5
qemu:rdmsr misc 0x000000ec00000000
!!! interrupt 2  intno:236 
HF_LMA_MASK 64 
[   37.623955] rdmsrl 5
qemu:rdmsr misc 0x000000ec00000000
!!! interrupt 2  intno:236 
HF_LMA_MASK 64 
[ !!! interrupt 2  intno:234 
HF_LMA_MASK 64 
  37.623955] rdmsrl 5
qemu:rdmsr misc 0x000000ec00000000
!!! interrupt 2  intno:236 
HF_LMA_MASK 64 
[   !!! interrupt 2  intno:234 
HF_LMA_MASK 64 
```

查询手册和linux源代码可知，进入死循环的原因是因为将`upid.puir`置为1后, 操作检测到, 会给自己发一个中断, 而对应用户态中断的UIVX恰好为236。至此我们定位到我们需要修改的中断处理函数为`do_interrupt64`。



## 指令相关的硬件逻辑实现

这里我们放置截止`2022年06月01日`的各个指令和逻辑实现方式。简单介绍实现过程中遇到的困难以及结局方式。

#### senduipi

指令翻译部分。

```c
    case 0x1c7: /* cmpxchg8b */
        if(prefixes & PREFIX_REPZ){ // SENDUIPI
            modrm = x86_ldub_code(env, s);
            gen_helper_senduipi(cpu_env, tcg_const_i32(modrm));
            break;
        }
        modrm = x86_ldub_code(env, s);
        mod = (modrm >> 6) & 3;
        switch ((modrm >> 3) & 7) {
        case 1: /* CMPXCHG8, CMPXCHG16 */
            if (mod == 3) {
                goto illegal_op;
            }
```

逻辑实现部分, 这部分主要遇到的困难是读写内存, 详细的问题解决方式主要在内存读写定位部分; 还遇到的问题是在尝试直接发中断的时候, 实现apic相关的逻辑, 这部分在接下来apic相关的部分介绍。

```c
void helper_senduipi(CPUX86State *env ,int reg_index){
    uint32_t uittsz = (uint32_t)env->uintr_misc;
    int uitte_index = env->regs[R_EAX];
    if (uitte_index > uittsz){
        raise_exception_ra(env, EXCP0D_GPF, GETPC());
    }

    int prot;
    CPUState *cs = env_cpu(env);

    // read tempUITTE from 16 bytes at UITTADDR+ (reg « 4);
    uint64_t uitt_phyaddress = get_hphys2(cs, (env->uintr_tt>>3)<<3 , MMU_DATA_LOAD, &prot);
    struct uintr_uitt_entry uitte;
    cpu_physical_memory_rw(uitt_phyaddress + (uitte_index<<4), &uitte, 16,false);

    // read tempUPID from 16 bytes at tempUITTE.UPIDADDR;// under lock
    uint64_t upid_phyaddress = get_hphys2(cs, uitte.target_upid_addr, MMU_DATA_LOAD, &prot);
    struct uintr_upid upid;
    cpu_physical_memory_rw(upid_phyaddress, &upid, 16, false);
    // tempUPID.PIR[tempUITTE.UV] := 1;
    upid.puir |= 1<<uitte.user_vec;
    
    bool sendNotify;
    //IF tempUPID.SN = tempUPID.ON = 0
    if((upid.nc.status&0x11) == 0){
    //THEN  tempUPID.ON := 1;   sendNotify := 1;
        upid.nc.status |= UPID_ON;
        sendNotify = true;
    }else{ // ELSE sendNotify := 0;
        sendNotify = false;
    }
    //write tempUPID to 16 bytes at tempUITTE.UPIDADDR;// release lock
    cpu_physical_memory_rw(upid_phyaddress, &upid, 16, true);
    if(sendNotify){
        qemu_log("direct sending\n");
        send_ipi(cpu_get_current_apic(), upid.nc.ndst, upid.nc.nv)
    }
}
```

#### uiret

指令翻译部分

```c
        case 0xec:
            if (prefixes & PREFIX_REPZ){ // UIRET
                gen_helper_uiret(cpu_env);
                gen_eob(s);
            }
            break;
```

指令逻辑实现部分, 这部分主要遇到的困难是栈不对齐的情况, 以及块翻译机制返回的问题。

```c
void helper_uiret(CPUX86State *env){
    in_uiret_called = true;
    recognized = false;
    target_ulong temprip, temprfalgs, temprsp;
    // env->regs[R_ESP] &= ~0xfLL; /* align stack */
    target_ulong esp = env->regs[R_ESP];
    // POPQ(esp, uirrv);
    POPQ(esp, temprip);
    POPQ(esp, temprfalgs);
    POPQ(esp, temprsp);
    env->eip = temprip;
    env->regs[R_ESP] = temprsp;
    env->eflags = (env->eflags & ~0x254dd5) |(temprfalgs & 0x254dd5);
    env->uintr_uif = 1;
}
```

#### stui

```c
        case 0xef: /* wrpkru */
            if(prefixes & PREFIX_REPZ){ // STUI
                env->uintr_uif = 1;
                break;
            }
            if (prefixes & PREFIX_LOCK) {
                goto illegal_op;
            }
            tcg_gen_concat_tl_i64(s->tmp1_i64, cpu_regs[R_EAX],
                                  cpu_regs[R_EDX]);
            tcg_gen_trunc_tl_i32(s->tmp2_i32, cpu_regs[R_ECX]);
            gen_helper_wrpkru(cpu_env, s->tmp2_i32, s->tmp1_i64);
            break;
```

#### 中断接受和处理

发现有用户态中断待处理后的逻辑:

```c
void helper_rrnzero(CPUX86State *env){ // 改
    target_ulong temprsp = env->regs[R_ESP];
    if(env->uintr_stackadjust &1){ // adjust[0] = 1
        env->regs[R_ESP] = env->uintr_stackadjust;
    }else{
        env->regs[R_ESP] -= env->uintr_stackadjust;
    }
    env->regs[R_ESP] &= ~0xfLL; /* align stack */
    target_ulong esp = env->regs[R_ESP];
    PUSHQ(esp, temprsp);
    PUSHQ(esp, env->eflags); // PUSHQ(esp, cpu_compute_eflags(env));
    PUSHQ(esp, env->eip);
    PUSHQ(esp, env->uintr_rr & 0x3f); // // 64-bit push; upper 58 bits pushed as 0
    env->uintr_rr = 0; // clear rr
    env->regs[R_ESP] = esp;
    env->eflags &= ~(TF_MASK | RF_MASK);
    env->eip = env->uintr_handler;
    env->uintr_uif = 0;
}
```

如何发现用户态中断, 主要遇到的问题是如何进行中断收尾, 开始只是单纯的读写内存, 最后定位到使用apic相关的接口进行实现才是正确的方法, 详细信息见apic相关的章节。

```c
if(intno == UINTR_UINV ){
        recognized = true;
        if(env->uintr_uif == 0){
            qemu_log("--uif not zero, return\n");
            helper_clear_eoi(env);
            return;
        }
        //查看当前的权级
        cpl = env->hflags & HF_CPL_MASK;
        qemu_log("-|-| perv: %d \n", cpl);
        if(cpl != 3){
            helper_clear_eoi(env);
            qemu_log("not in user mode return\n");
            return;
        }
        int prot;
        CPUState *cs = env_cpu(env);
        uint64_t upid_phyaddress = get_hphys2(cs, env->uintr_pd, MMU_DATA_LOAD, &prot);
        uintr_upid upid;
        cpu_physical_memory_rw(upid_phyaddress, &upid, 16, false);
        upid.nc.status &= (~1); // clear on
        if(upid.puir != 0){
            env->uintr_rr = upid.puir;
            upid.puir = 0; // clear puir
            cpu_physical_memory_rw(upid_phyaddress, &upid, 16, true); // write back
            send = true;
        }
        cpu_physical_memory_rw(upid_phyaddress, &upid, 16, true);
        helper_clear_eoi(env);
        if(send)helper_rrnzero(env);
        return;
    }
```



### APIC相关

这个小结主要介绍apic相关的问题, 在指令实现过程中, 和apic相关的主要有在接受中断时清除eoi是所做的操作, 没有正确处理遇到的问题是cpu会进入关中断的死状态, 内核无法调度。其次相关的是直接发中断的过程, 设计核间中断的传递和处理, 主要是弄清楚参数的含义以及传递规范, 同时对中断处理也做出了一定的修改。

#### EOI

开始在清除eoi时，采用了查页表的方法然后写入物理地址。

```c
        int prot;
        uint64_t APICaddress = get_hphys2(cs, APIC_DEFAULT_ADDRESS, MMU_DATA_LOAD, &prot);
        uint64_t EOI;
        uint64_t zero = 0;
        cpu_physical_memory_rw(APICaddress + 0xb0, &EOI, 8, false);
        qemu_log("the physical address of APIC 0x%lx   the EOI content: 0x%lx\n", APICaddress,EOI);
        cpu_physical_memory_rw(APICaddress + 0xb0, &zero, 4, true);
```

以上的实现在使用了用户态中断程序之后出现cpu调度的问题, 操作系统报错如下。

```shell
/ # [   27.363369] rcu: INFO: rcu_sched detected stalls on CPUs/tasks:
[   27.364142] rcu: 	0-...!: (0 ticks this GP) idle=472/0/0x0 softirq=149/149 fqs=0  (false positive?)
[   27.364142] 	(detected by 1, t=21002 jiffies, g=-891, q=18)
[   27.364142] Sending NMI from CPU 1 to CPUs 0:
[   24.853640] NMI backtrace for cpu 0
[   24.853640] CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.15.0-rc1+ #6
[   24.853640] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org 04/01/2014
[   24.853640] RIP: 0010:amd_e400_idle+0x16/0x40
[   24.853640] Code: b6 00 5b 48 c7 c7 80 02 25 9e 5d 41 5c 41 5d e9 90 01 b7 00 48 8b 05 49 1f 65 01 a8 10 75 0c eb 07 0f 00 2d 34 c0 fd 00 fb f4 <c3> bf 01 00 00 00 e8 1f 29 0c 04
[   24.853640] RSP: 0018:ffffffff9e203ea0 EFLAGS: 00000246
[   24.853640] RAX: 000000000001a940 RBX: 0000000000000000 RCX: 0000000000000000
[   24.853640] RDX: ffff96f9bea264a0 RSI: ffffffff9e203e30 RDI: 0000000000001472
[   24.853640] RBP: ffffffff9e214940 R08: 0000000000001471 R09: ffff96f98112d1c0
[   24.853640] R10: ffff96f9bea25740 R11: 0000000000025400 R12: ffffffff9e214940
[   24.853640] R13: ffffffff9e214940 R14: 0000000000000000 R15: 0000000000000000
[   24.853640] FS:  0000000000000000(0000) GS:ffff96f9bea00000(0000) knlGS:0000000000000000
[   24.853640] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[   24.853640] CR2: 00007f635c574e78 CR3: 000000003720c000 CR4: 00000000000006f0
[   24.853640] Call Trace:
[   24.853640]  default_idle_call+0x2c/0xa0
[   24.853640]  do_idle+0x1d9/0x230
[   24.853640]  cpu_startup_entry+0x14/0x20
[   24.853640]  start_kernel+0x673/0x698
[   24.853640]  secondary_startup_64_no_verify+0xc2/0xcb
[   27.364142] rcu: rcu_sched kthread timer wakeup didn't happen for 20999 jiffies! g-891 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402
[   27.364142] rcu: 	Possible timer handling issue on cpu=0 timer-softirq=138
[   24.853640] INFO: NMI handler (nmi_cpu_backtrace_handler) took too long to run: 29.077 msecs
[   27.364142] rcu: rcu_sched kthread starved for 21002 jiffies! g-891 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402 ->cpu=0
[   27.364142] rcu: 	Unless rcu_sched kthread gets sufficient CPU time, OOM is now expected behavior.
[   27.364142] rcu: RCU grace-period kthread stack dump:
[   27.364142] task:rcu_sched       state:I stack:14856 pid:   10 ppid:     2 flags:0x00004000
[   27.364142] Call Trace:
[   27.364142]  __schedule+0x26c/0x6c0
[   27.364142]  schedule+0x3f/0xa0
[   27.364142]  schedule_timeout+0x18b/0x290
[   27.364142]  ? del_timer_sync+0x30/0x30
[   27.364142]  rcu_gp_fqs_loop+0xee/0x3b0
[   27.364142]  rcu_gp_kthread+0xe2/0x1c0
[   27.364142]  ? rcu_gp_cleanup+0x460/0x460
[   27.364142]  kthread+0x122/0x140
[   27.364142]  ? set_kthread_struct+0x40/0x40
[   27.364142]  ret_from_fork+0x22/0x30
[   27.364142] rcu: Stack dump where RCU GP kthread last ran:
[   27.364142] Sending NMI from CPU 1 to CPUs 0:
```

引发这个报错的原因较多, 参考`https://blog.csdn.net/m0_37105371/article/details/118367133`, 初步判断很可能和中断控制相关, 在x86中关闭中断需要通过内存映射访问apic的寄存器进行控制, 之前的实现通过qemu中查页表的方式实现, 但可能在qemu中这样的内存映射不会在这里的接口呈现, 尝试寻找apic相关的线索。

### 尝试寻找apic相关的代码

#### 这里我们找到sipi相关的流程线

```c
//target/i386/sysemu/seg_helper.c/x86_cpu_exec_interrupt
        if(Debug) printf("x86 cpu exec interrupt called sipi \n");
        do_cpu_sipi(cpu);

//target/i386/helper.c/do_cpu_sipi
void do_cpu_sipi(X86CPU *cpu)
{
    apic_sipi(cpu->apic_state); //此处调用的是第一个函数
}

//hw/intc/apic.c
void apic_sipi(DeviceState *dev)
{   
    if(Debug)printf("qemu: apic sipi called\n");
    APICCommonState *s = APIC(dev);

    cpu_reset_interrupt(CPU(s->cpu), CPU_INTERRUPT_SIPI);

    if (!s->wait_for_sipi)
        return;
    cpu_x86_load_seg_cache_sipi(s->cpu, s->sipi_vector);
    s->wait_for_sipi = 0;
}
```

可以在linux启动的日志中看到相关的输出:

```shell
[    0.334116] x86: Booting SMP configuration:
x86 cpu exec interrupt called sipi 
qemu: apic sipi called
x86 cpu exec interrupt called sipi 
qemu: apic sipi called
[    0.334220] .... node  #0, CPUs:  
```

根据以上的文件组织路径, 我们尝试在clear_eoi中构建相同的调用路径, 调用到apic.c中的函数



### eoi线索

```c
static void apic_eoi(APICCommonState *s) //可能和eoi有关, 但是是静态函数

// apic_eoi调用位置
static void apic_mem_write(void *opaque, hwaddr addr, uint64_t val,unsigned size){
  //其中的语句, 但函数的第一个参数来源不明
  case 0x0b: /* EOI */
  apic_eoi(s);
}

//最后函数被放入了一个结构体内
static const MemoryRegionOps apic_io_ops = {
    .read = apic_mem_read,
    .write = apic_mem_write,
    .impl.min_access_size = 1,
    .impl.max_access_size = 4,
    .valid.min_access_size = 1,
    .valid.max_access_size = 4,
    .endianness = DEVICE_NATIVE_ENDIAN,
};

//最后这个结构体被传入一个函数
static void apic_realize(DeviceState *dev, Error **errp)
{
  //.....
    memory_region_init_io(&s->io_memory, OBJECT(s), &apic_io_ops, s, "apic-msi",APIC_SPACE_SIZE);
	//......
}
/* apic在代码中一般是一个APICCommonState
 include/hw/i386/apic_internal.h
*/
struct APICCommonState {
    /*< private >*/
    DeviceState parent_obj;
    /*< public >*/

    MemoryRegion io_memory;
    X86CPU *cpu;
    uint32_t apicbase;
    uint8_t id; /* legacy APIC ID */
    uint32_t initial_apic_id;
    uint8_t version;
    uint8_t arb_id;
    uint8_t tpr;
    uint32_t spurious_vec;
    uint8_t log_dest;
    uint8_t dest_mode;
    uint32_t isr[8];  /* in service register */
    uint32_t tmr[8];  /* trigger mode register */
    uint32_t irr[8]; /* interrupt request register */
    uint32_t lvt[APIC_LVT_NB];
    uint32_t esr; /* error register */
    uint32_t icr[2];

    uint32_t divide_conf;
    int count_shift;
    uint32_t initial_count;
    int64_t initial_count_load_time;
    int64_t next_time;
    QEMUTimer *timer;
    int64_t timer_expiry;
    int sipi_vector;
    int wait_for_sipi;

    uint32_t vapic_control;
    DeviceState *vapic;
    hwaddr vapic_paddr; /* note: persistence via kvmvapic */
    bool legacy_instance_id;
};

/*  MemoryRegion定义
		include/exec/memory.h
*/
struct MemoryRegion {
    Object parent_obj;

    /* private: */

    /* The following fields should fit in a cache line */
    bool romd_mode;
    bool ram;
    bool subpage;
    bool readonly; /* For RAM regions */
    bool nonvolatile;
    bool rom_device;
    bool flush_coalesced_mmio;
    uint8_t dirty_log_mask;
    bool is_iommu;
    RAMBlock *ram_block;
    Object *owner;

    const MemoryRegionOps *ops;
    void *opaque;
    MemoryRegion *container;
    int mapped_via_alias; /* Mapped via an alias, container might be NULL */
    Int128 size;
    hwaddr addr;
    void (*destructor)(MemoryRegion *mr);
    uint64_t align;
    bool terminates;
    bool ram_device;
    bool enabled;
    bool warning_printed; /* For reservations */
    uint8_t vga_logging_count;
    MemoryRegion *alias;
    hwaddr alias_offset;
    int32_t priority;
    QTAILQ_HEAD(, MemoryRegion) subregions;
    QTAILQ_ENTRY(MemoryRegion) subregions_link;
    QTAILQ_HEAD(, CoalescedMemoryRange) coalesced;
    const char *name;
    unsigned ioeventfd_nb;
    MemoryRegionIoeventfd *ioeventfds;
    RamDiscardManager *rdm; /* Only for RAM */
};
```

看到这里我们希望做到调用`apic_eoi`这个函数, 因此要寻找`apic_mem_write`这个函数,为此要寻找对应的apic 设备的`MemoryRegion`中的`MemoryRegionOps`中的`write`函数。另一种方法时直接调用EOI，但是我们需要找到正确的参数进行传递。



我们尝试对关键节点添加pin进行监控。

```c
static void do_interrupt64()
	//....
		if(intno == UINTR_UINV ){
        qemu_log("recognize uintr\n");
        recognized = true; //在识别到用户态中断后看eoi是否被写
    }

void helper_uiret(CPUX86State *env){ // 进入uiret后结束监控
    if(Debug)qemu_log("\n\n---------\nhelper uiret called,\neip: 0x%lx | sp: 0x%lx\n", env->eip,env->regs[R_ESP]);
    in_uiret_called = true;
    recognized = false;
 
static void apic_mem_write(void *opaque, hwaddr addr, uint64_t val,unsigned size){
  //....
     case 0x0b: /* EOI */
        if(Debug && recognized)qemu_log("~ ~ ~ ~EOI called in mem wirte\n");
        apic_eoi(s);
        break;
}
  
static void apic_realize(DeviceState *dev, Error **errp)
{   
    if(Debug)qemu_log("~ ~ ~ ~apic realize called\n");
  //...
}

// 监控自己写的eoi的函数中监控apic数据结构的地址
static void helper_clear_eoi(CPUX86State *env){
        CPUState *cs = env_cpu(env);
  //..
        DeviceState *dev = cpu_get_current_apic();
        X86CPU *cpu = X86_CPU(cs);
        qemu_log("~ ~ ~ ~ addr of curdev 0x%p | apic state 0x%p \n", dev, cpu->apic_state);
        // APICCommonState *apic = APIC_COMMON(cpu->apic_state);
        
}
```

通过grep查询输出前缀，输出相邻的3行。结果表示，EOI没有真正的被触发

```shell
qemu-system-x86_64: warning: expand featrue called

qemu-system-x86_64: warning: x86 cpu filter feature called
~ ~ ~ ~apic realize called # cpu初始化
qemu-system-x86_64: warning: expand featrue called

qemu-system-x86_64: warning: x86 cpu filter feature called
~ ~ ~ ~apic realize called # 第二个cpu初始化
x86 cpu exec interrupt called sipi
qemu: apic sipi called
SeaBIOS (version rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org)
--
!!! interrupt 2  intno:236
recognize uintr
the physical address of APIC 0x7f1e9ea1e610   the EOI content: 0x0
~ ~ ~ ~ addr of curdev 0x0x55f6bb8fc400 | apic state 0x0x55f6bb8fc400 # 两种方式取到的地址一致，说明是一个设备
------
rrnzero called handler: 0x401ec0  rr: 0x1
origin |esp 0x7ffd38853420  | eip 0x49db3f | eflags: 0x202
--
--------

xxxx   in uiret called after exec tb;
~ ~ ~ ~EOI called in mem wirte # 这条输出可能来自于其他地方
[    6.145380] send: unregister sender uintrfd 3 for task=78 ret 0
[    6.147092] debug!
[    6.147969] rdmsrl 1
```

以下样例没有eoi相关的输出

```shell
qemu-system-x86_64: warning: expand featrue called

qemu-system-x86_64: warning: x86 cpu filter feature called
~ ~ ~ ~apic realize called
qemu-system-x86_64: warning: expand featrue called

qemu-system-x86_64: warning: x86 cpu filter feature called
~ ~ ~ ~apic realize called
x86 cpu exec interrupt called sipi
qemu: apic sipi called
SeaBIOS (version rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org)
--
!!! interrupt 2  intno:236
recognize uintr
the physical address of APIC 0x7f7729a9f610   the EOI content: 0x0
~ ~ ~ ~ addr of curdev 0x0x55c04290e400 | apic state 0x0x55c04290e400
------
rrnzero called handler: 0x401ec0  rr: 0x1
origin |esp 0x7ffc37502ce0  | eip 0x49db3f | eflags: 0x202
```

尝试仿照sipi方式进行实现，主要是如何在调用方找到传入的参数：

```c
static void apic_eoi(APICCommonState *s) //需要传入的参数是APICCommonState
  
void apic_sipi(DeviceState *dev){   
    APICCommonState *s = APIC(dev); // 在这里找到从DeviceState转化为APICCommonState的方式
  //..
}

//target/i386/helper.c 
void do_cpu_sipi(X86CPU *cpu)  // X86CPU的一个属性是DeviceState * 类型
{
    apic_sipi(cpu->apic_state);
}
```

再根据pin的输出, 可知cpu_get_current_apic() 和 cpu结构体中的apic_state地址相同, 说明可以用这样的方式进行传参。:

```c
~ ~ ~ ~ addr of curdev 0x0x55c04290e400 | apic state 0x0x55c04290e400

        DeviceState *dev = cpu_get_current_apic();
        X86CPU *cpu = X86_CPU(cs);
        qemu_log("~ ~ ~ ~ addr of curdev 0x%p | apic state 0x%p \n", dev, cpu->apic_state);
```

在`//hw/intc/apic.c`中编写新的可直接调用的eio函数:

```c
void apic_clear_eoi(DeviceState *dev){
    APICCommonState *s = APIC(dev);
    int isrv;
    isrv = get_highest_priority_int(s->isr);
    if (isrv < 0)
        return;
    apic_reset_bit(s->isr, isrv);
    if (!(s->spurious_vec & APIC_SV_DIRECTED_IO) && apic_get_bit(s->tmr, isrv)) {
        ioapic_eoi_broadcast(isrv);
    }
    apic_sync_vapic(s, SYNC_FROM_VAPIC | SYNC_TO_VAPIC);
    apic_update_irq(s);
}

//在中断处理部分调用的函数：
static void helper_clear_eoi(CPUX86State *env){
        CPUState *cs = env_cpu(env);
        DeviceState *dev = cpu_get_current_apic();
        X86CPU *cpu = X86_CPU(cs);
        qemu_log("~ ~ ~ ~ addr of curdev 0x%p | apic state 0x%p \n", dev, cpu->apic_state);
        apic_clear_eoi(dev);
}
```

随后运行程序，程序可以正常结束，且可以多次执行，操作系统不报错。



#### 直接发中断

本部分主要介绍借助apic进行直接发中断相关的逻辑, 主要的问题是函数参数的传递, 在实现过程中, 还有一个有关权级的小问题也值得讨论。

在`hw/intc/apic.c` 中存在比较符合功能的函数`apic_deliver`, 但是其中的参数意义以及如何传递是个问题, 经过一些尝试以及和学长的讨论, 最后确定传递参数的形式, 并编写了新的函数。

```c
static void apic_deliver(DeviceState *dev, uint8_t dest, uint8_t dest_mode,
                         uint8_t delivery_mode, uint8_t vector_num,
                         uint8_t trigger_mode) { //...
}

void send_ipi(DeviceState *dev, uint8_t dest, uint8_t nv){
    qemu_mutex_lock_iothread();
    apic_deliver(dev, dest, 0 ,APIC_DM_FIXED, nv, APIC_TRIGGER_EDGE);
    qemu_mutex_unlock_iothread();
}
```

`helper_senduipi`函数结尾添加如下逻辑:

```c
    if(sendNotify){
        if(current)qemu_log("direct sending\n");
        send_ipi(cpu_get_current_apic(), upid.nc.ndst, upid.nc.nv);
    }
```

但是在运行后, 内核会出现panic的情况, 主要的原因是在内核态执行了用户程序的代码。这应当和uintr中断接受处理相关, 在中断处理程序中查看接受中断时的权级。注意到确实是在内核态跳转到了handler从而报错。

```c
    bool send = false;
    if(intno == UINTR_UINV ){
        //查看当前的权级
        cpl = env->hflags & HF_CPL_MASK;
        qemu_log("-|-| perv: %d \n", cpl);
        if(env->uintr_uif == 0){
            qemu_log("--uif not zero, return\n");
            helper_clear_eoi(env);
            return;
        }
```

在中断处理中添加权级的识别和处理:

```c
        //查看当前的权级
        cpl = env->hflags & HF_CPL_MASK;
        qemu_log("-|-| perv: %d \n", cpl);
        if(env->uintr_uif == 0){
            qemu_log("--uif not zero, return\n");
            helper_clear_eoi(env);
            return;
        }
        if(cpl != 3){
            helper_clear_eoi(env);
            qemu_log("not in user mode return\n");
            return;
        }
```

随后程序可以正常结束。

验证是否成功发中断, 在内核给自己发中断的逻辑中添加pin, 如果是内核给自己发中断实现uintr, 则说明直接发中断没有成功, 否则即成功。

```c
		if (READ_ONCE(upid->puir)){
			printk("sending self ipi\n");
			apic->send_IPI_self(UINTR_NOTIFICATION_VECTOR);
		}
```

运行`uipi_sample`, 得到如下结果:

```shell
/ # uipi_sample 
[   81.653132] uintr_register_handler called
[   81.653936] recv: register handler task=93 flags 0 handler 401de5 ret 0
[   81.654885] uintr_create_fd called
[   81.655452] recv: Alloc vector success uintrfd 3 uvec 0 for task=93
Receiver enabled interrupts
[   81.660718] uintr_register_sender called
[   81.663076] send: register sender task=94 flags 0 ret(uipi_id)=0
Sending IPI from sender thread
direct sending
[   81.665972] uintr_unregister_sender called
[   81.666642] send: unregister sender uintrfd 3 for task=94 ret 0
-|-| perv: 0 
not in user mode return
[   81.667348] sending self ipi
-|-| perv: 3 
        -- User Interrupt handler --
[   81.669100] recv: Release uintrfd for r_task 93 uvec 0
[   81.669775] uintr_unregister_handler called
[   81.670522] recv: unregister handler task=93 flags 0 ret 0
```

可以看到内核还是给自己发中断的逻辑。经过和学长讨论，因为接收方是不断调用sleep，而在sleep就非常依赖内核的调度, 如果尝试不进行sleep系统调用, 一直while 死循环, 一直让接收方保持活跃且处于用户态, 则可能成功。

为此编译死循环等待的接受放进行调试, 发现没有`sending self ipi`, 直接发送ipi成功。

```c
/ # nosleep 
[  255.396726] uintr_register_handler called
[  255.397693] recv: register handler task=95 flags 0 handler 401de5 ret 0
[  255.398604] uintr_create_fd called
[  255.399228] recv: Alloc vector success uintrfd 3 uvec 0 for task=95
Receiver enabled interrupts
[  255.409186] uintr_register_sender called
[  255.409434] send: register sender task=96 flags 0 ret(uipi_id)=0
Sending IPI from sender thread
direct sending
[  255.419028] uintr_unregister_sender called
[  255.423430] send: unregister sender uintrfd 3 for task=96 ret 0
[  255.419455] sending self ipi
-|-| perv: 3 
        -- User Interrupt handler --
[  255.440512] recv: Release uintrfd for r_task 95 uvec 0
[  255.444517] uintr_unregister_handler called
[  255.444816] recv: unregister handler task=95 flags 0 ret 0
Success
```

正确实现:

注意到在跑`uintrfd-bi`这个性能测试程序的时候, 还是有大量的操作系统自己发中断的过程, 猜想可能是直接发中断过程还是有不正确的地方, 开始尝试找bug。

在接收方添加pins:

```c
        if(!uif_enable(env)){
            DeviceState *dev = cpu_get_current_apic();
            int id = get_apic_id(dev);
            qemu_log("--uif zero,prev:%d | id:%d return\n",cpl, id);
            rrzero_count +=1; 
            if(rrzero_count > 200){
                qemu_log("too many zeros, exit\n");
                exit(2);
            }
            helper_clear_eoi(env);
            return;
        }
        qemu_log("the upid addr is:0x%lx upir is 0x%lx apic id is %d\n", env->uintr_pd, upid.puir, get_apic_id(cpu_get_current_apic()));
```

这里查看了接受方在收到中断时, 读取的upid地址, upir的值, 当前的核号。

在发送方添加pins:

```c
    cpu_physical_memory_rw(upid_phyaddress, &upid, 16, true);
    qemu_mutex_unlock_iothread();
    qemu_log("send upid addr is 0x%lx apic id:%d dest:%d\n",uitte.target_upid_addr,get_apic_id(cpu_get_current_apic()),upid.nc.ndst);
```

这里查看了我们写入的upid的地址, 以及当前的核号, 目标的核号。

运行`uintrfd-bi`后得到如下输出:

```shell
/home/xcd/qemu_uintr/ipc-bench/build/source/uintrfd # ./uintrfd-bi -c 2
send upid addr is 0xffffa2aa01ccfdc0 apic id:0 dest:256
perv: 0 | id:1 not in user mode return
[  408.509039] sending self ipi
the upid addr is:0xffffa2aa01ccfdc0 upir is 0x2 apic id is 1
send upid addr is 0xffffa2aa056fa280 apic id:1 dest:0
the upid addr is:0xffffa2aa01ccfdc0 upir is 0x0 apic id is 1
[  408.511343] sending self ipi
the upid addr is:0xffffa2aa056fa280 upir is 0x1 apic id is 0
send upid addr is 0xffffa2aa01ccfdc0 apic id:0 dest:256
the upid addr is:0xffffa2aa056fa280 upir is 0x0 apic id is 0
[  408.513585] sending self ipi
the upid addr is:0xffffa2aa01ccfdc0 upir is 0x2 apic id is 1
send upid addr is 0xffffa2aa056fa280 apic id:1 dest:0
the upid addr is:0xffffa2aa01ccfdc0 upir is 0x0 apic id is 1
[  408.516225] sending self ipi
the upid addr is:0xffffa2aa056fa280 upir is 0x1 apic id is 0
```

注意到这里dest呈现0和256的交替变化, 但是理论上应当是0和1交替变化。仔细查询手册, 在手册的一个脚注中找到如下:

```
 For xAPIC mode (which is virtualized if the “virtualize APIC accesses” VM-execution control is 1), the destination APIC ID is in byte 1 
(not byte 0) of the UPID’s 4-byte NDST field.
```

可知正确的id 需要ndst右移8位。

其次, 我们注意到在没有系统调度的发和收之间, 出现了uipir=0的情况, 并且出现了自己给自己发送的情况。发送核号为1, 接收放也为1。upir为零则表示没有中断。而写入和upid和收到的upid地址不同同样印证了这一点。

```
send upid addr is 0xffffa2aa056fa280 apic id:1 dest:0
the upid addr is:0xffffa2aa01ccfdc0 upir is 0x0 apic id is 1
```

在发送方传参的内容中, 当时和学长讨论, 传入的是当前核的apic以及目标核号。

```c
    if(sendNotify){
        uint8_t realdst = upid.nc.ndst >> 8;
        send_ipi(cpu_get_current_apic(),realdst, upid.nc.nv);
    }
void send_ipi(DeviceState *dev,uint8_t dest, uint8_t nv){
    qemu_mutex_lock_iothread();
    apic_deliver(dev, dest, 0 ,APIC_DM_FIXED, nv, APIC_TRIGGER_EDGE);
    qemu_mutex_unlock_iothread();
}
```

推测一个可能的原因是需要传入目标核的apic才能work。

做以下尝试:

```c
static void apic_deliver2(uint8_t dest, uint8_t dest_mode,
                         uint8_t delivery_mode, uint8_t vector_num,
                         uint8_t trigger_mode)
{
    APICCommonState *s = local_apics[dest]; // 直接从apic设备数组中按标号读取
    uint32_t deliver_bitmask[MAX_APIC_WORDS];
    int dest_shorthand = (s->icr[0] >> 18) & 3;
    APICCommonState *apic_iter;

    switch (dest_shorthand) {
    case 0:
        apic_get_delivery_bitmask(deliver_bitmask, dest, dest_mode);
        break;
    case 1:
        memset(deliver_bitmask, 0x00, sizeof(deliver_bitmask));
        apic_set_bit(deliver_bitmask, s->id);
        break;
    case 2:
///.....
            return;
    }

    apic_bus_deliver(deliver_bitmask, delivery_mode, vector_num, trigger_mode);
}

void send_ipi(uint8_t dest, uint8_t nv){// 不要求传入自己的apic
    qemu_mutex_lock_iothread();
    apic_deliver2(dest, 0 ,APIC_DM_FIXED, nv, APIC_TRIGGER_EDGE);
    qemu_mutex_unlock_iothread();
}

    if(sendNotify){
        uint8_t realdst = upid.nc.ndst >> 8;
        send_ipi(realdst, upid.nc.nv);
    }
```

随后运行得到输出:

```shell
/home/xcd/qemu_uintr/ipc-bench/build/source/uintrfd # ./uintrfd-bi -c 20
send upid addr is 0xffffa419441a42c0 apic id:1 dest:0
[   48.266874] sending self ipi
the upid addr is:0xffffa419441a42c0 upir is 0x2 apic id is 0
send upid addr is 0xffffa419412b4ec0 apic id:0 dest:256
[   48.269552] sending self ipi
the upid addr is:0xffffa419412b4ec0 upir is 0x1 apic id is 1
send upid addr is 0xffffa419441a42c0 apic id:1 dest:0
the upid addr is:0xffffa419441a42c0 upir is 0x2 apic id is 0
send upid addr is 0xffffa419412b4ec0 apic id:0 dest:256
the upid addr is:0xffffa419412b4ec0 upir is 0x1 apic id is 1
send upid addr is 0xffffa419441a42c0 apic id:1 dest:0
the upid addr is:0xffffa419441a42c0 upir is 0x2 apic id is 0
send upid addr is 0xffffa419412b4ec0 apic id:0 dest:256
the upid addr is:0xffffa419412b4ec0 upir is 0x1 apic id is 1
send upid addr is 0xffffa419441a42c0 apic id:1 dest:0
```

注意到系统调度明显减少，发送和接收方相互交换且呼应正确，问题得到解决。随后测试发现性能大幅提升。

## Xsave 相关实现

搜索xsave, 找到如下引用:

```c
//target/i386/cpu.h
#define XSTATE_FP_BIT                   0
#define XSTATE_SSE_BIT                  1
#define XSTATE_YMM_BIT                  2
#define XSTATE_BNDREGS_BIT              3
#define XSTATE_BNDCSR_BIT               4
#define XSTATE_OPMASK_BIT               5
#define XSTATE_ZMM_Hi256_BIT            6
#define XSTATE_Hi16_ZMM_BIT             7
#define XSTATE_PKRU_BIT                 9
#define XSTATE_UINTR_BIT                14
//改 XSTAVE 根据手册,添加对应的bitmap标识
#define XSTATE_XTILE_CFG_BIT            17
#define XSTATE_XTILE_DATA_BIT           18
#define XSTATE_UINTR_MASK               (1ULL << XSTATE_UINTR_BIT)
#define XSTATE_FP_MASK                  (1ULL << XSTATE_FP_BIT)
#define XSTATE_SSE_MASK                 (1ULL << XSTATE_SSE_BIT)
#define XSTATE_YMM_MASK                 (1ULL << XSTATE_YMM_BIT)
#define XSTATE_BNDREGS_MASK             (1ULL << XSTATE_BNDREGS_BIT)
#define XSTATE_BNDCSR_MASK              (1ULL << XSTATE_BNDCSR_BIT)
#define XSTATE_OPMASK_MASK              (1ULL << XSTATE_OPMASK_BIT)
#define XSTATE_ZMM_Hi256_MASK           (1ULL << XSTATE_ZMM_Hi256_BIT)
#define XSTATE_Hi16_ZMM_MASK            (1ULL << XSTATE_Hi16_ZMM_BIT)
#define XSTATE_PKRU_MASK                (1ULL << XSTATE_PKRU_BIT)
#define XSTATE_XTILE_CFG_MASK           (1ULL << XSTATE_XTILE_CFG_BIT)
#define XSTATE_XTILE_DATA_MASK          (1ULL << XSTATE_XTILE_DATA_BIT)

//target/i386/tcg/fpuhelper.c
static bool Debug = true;
static void do_xsave(CPUX86State *env, target_ulong ptr, uint64_t rfbm,
                     uint64_t inuse, uint64_t opt, uintptr_t ra)
{
    uint64_t old_bv, new_bv;
    if(Debug)printf("do xsave called\n"); // 改 xsave
    /* The OS must have enabled XSAVE.  */
    if (!(env->cr[4] & CR4_OSXSAVE_MASK)) {
        raise_exception_ra(env, EXCP06_ILLOP, ra);
    }

    /* The operand must be 64 byte aligned.  */
    if (ptr & 63) {
        raise_exception_ra(env, EXCP0D_GPF, ra);
    }
    /* Never save anything not enabled by XCR0.  */
    rfbm &= env->xcr0;
    opt &= rfbm;
    if (opt & XSTATE_FP_MASK) {
        do_xsave_fpu(env, ptr, ra);
    }
    if (rfbm & XSTATE_SSE_MASK) {
        /* Note that saving MXCSR is not suppressed by XSAVEOPT.  */
        do_xsave_mxcsr(env, ptr, ra);
    }
    if (opt & XSTATE_SSE_MASK) {
        do_xsave_sse(env, ptr, ra);
    }
    if (opt & XSTATE_BNDREGS_MASK) {
        do_xsave_bndregs(env, ptr + XO(bndreg_state), ra);
    }
    if (opt & XSTATE_BNDCSR_MASK) {
        do_xsave_bndcsr(env, ptr + XO(bndcsr_state), ra);
    }
    if (opt & XSTATE_PKRU_MASK) {
        do_xsave_pkru(env, ptr + XO(pkru_state), ra);
    }
    if (opt & XSTATE_UINTR_MASK) {// 改 
        do_xsave_uintr(env, ptr , ra);
    }

    /* Update the XSTATE_BV field.  */
    old_bv = cpu_ldq_data_ra(env, ptr + XO(header.xstate_bv), ra);
    new_bv = (old_bv & ~rfbm) | (inuse & rfbm);
    cpu_stq_data_ra(env, ptr + XO(header.xstate_bv), new_bv, ra);
}

/*
在这里介绍一下一个宏展开
#define XO(X)  offsetof(X86XSaveArea, X)
#define offsetof(TYPE, MEMBER) __builtin_offsetof (TYPE, MEMBER)
__builtin_offsetof 的作用是什么?
这里使用的是一个利用编译器技术的小技巧，即先求得结构成员变量在结构体中的相对于结构体的首地址的偏移地址，然后根据结构体的首地址为0，从而得出该偏移地址就是该结构体变量在该结构体中的偏移，即：该结构体成员变量距离结构体首的距离。
*/

static void do_xsave_uintr(CPUX86State *env, target_ulong ptr, uintptr_t ra){ //改
    cpu_stq_data_ra(env, ptr, env->uintr_handler, ra);
    cpu_stq_data_ra(env, ptr+8, env->uintr_stackadjust, ra);
    cpu_stq_data_ra(env, ptr+16, env->uintr_misc, ra);
    cpu_stq_data_ra(env, ptr+24, env->uintr_pd, ra);
    cpu_stq_data_ra(env, ptr+32, env->uintr_rr, ra);
    cpu_stq_data_ra(env, ptr+40, env->uintr_tt, ra);
}

static void do_xrstor_uintr(CPUX86State *env, target_ulong ptr, uintptr_t ra){ //改
    env->uintr_handler = cpu_ldq_data_ra(env, ptr, ra);
    env->uintr_stackadjust = cpu_ldq_data_ra(env, ptr+8, ra);
    env->uintr_misc = cpu_ldq_data_ra(env, ptr+16, ra);
    env->uintr_pd = cpu_ldq_data_ra(env, ptr+24, ra);
    env->uintr_rr = cpu_ldq_data_ra(env, ptr+32, ra);
    env->uintr_tt = cpu_ldq_data_ra(env, ptr+40, ra);
}

static void clear_uintr_reg(CPUX86State *env){ // 改
    env->uintr_handler=0;
    env->uintr_stackadjust=0;
    env->uintr_misc=0;
    env->uintr_pd=0;
    env->uintr_rr=0;
    env->uintr_tt=0;
}

//在helper_xrstor中添加如下
	if (rfbm & XSTATE_UINTR_MASK){ // 改
        if (xstate_bv & XSTATE_UINTR_MASK) {
            do_xrstor_uintr(env, ptr + XO(uintr_state), ra);
        } else {
            clear_uintr_reg(env);
        }
  }

//target/i386/tcg/tcg-cpu.h
typedef struct X86XSaveArea {
    X86LegacyXSaveArea legacy;
    X86XSaveHeader header;

    /* Extended save areas: startoffset:0x240 */

    /* AVX State: */
    XSaveAVX avx_state;

    /* Ensure that XSaveBNDREG is properly aligned. */
    uint8_t padding[XSAVE_BNDREG_OFFSET
                    - sizeof(X86LegacyXSaveArea)
                    - sizeof(X86XSaveHeader)
                    - sizeof(XSaveAVX)];
    /* MPX State: */
    XSaveBNDREG bndreg_state;
    XSaveBNDCSR bndcsr_state;
    /* AVX-512 State: */
    XSaveOpmask opmask_state;
    XSaveZMM_Hi256 zmm_hi256_state;
    XSaveHi16_ZMM hi16_zmm_state;
    /* PKRU State: */
    XSavePKRU pkru_state;
    XSaveUINTR uintr_state; // 改
} X86XSaveArea;


//target/i386/cpu.h 添加如下区域
/* Ext. save area 14: UINTR state*/ 
typedef struct XSaveUINTR {
    uint64_t handler;
    uint64_t stack_adjust;
    struct{
        uint32_t uittsz;
        uint8_t uinv;
        uint16_t reserved;
        uint8_t uif; // bit7 is the uif
    };
    uint64_t upidaddr;
    uint64_t uirr;
    uint64_t uittaddr;
    
}XSaveUINTR;

```



## 栈偏移研究以及反汇编分析

在实现uiret时, 有遇到的问题是, 在恢复上下文以及保存上下文





# 实现异步系统调用

## 命令手册

```
netstat -tunlp | grep 8000
./web & nc 127.0.0.1 8000 -v < test.txt

```





### 内核在qemu中无法联网的情况

```
具体表现为：
ifconfig 为空
ping 127.0.0.1 显示unreachable
```



### 在qemu上跑ubuntu, 发现可以联网

```
root@ubuntu:~# ifconfig
enp0s2: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255
        inet6 fe80::5054:ff:fe12:3456  prefixlen 64  scopeid 0x20<link>
        inet6 fec0::5054:ff:fe12:3456  prefixlen 64  scopeid 0x40<site>
        ether 52:54:00:12:34:56  txqueuelen 1000  (Ethernet)
        RX packets 97  bytes 20020 (20.0 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 22  bytes 17534 (17.5 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
        device interrupt 22  memory 0xfeb80000-feba0000

lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10<host>
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 84  bytes 6324 (6.3 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 84  bytes 6324 (6.3 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
       
root@ubuntu:~# ping 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=6.85 ms
64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.751 ms
64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.784 ms

root@ubuntu:~# cat /etc/network/interfaces
# ifupdown has been replaced by netplan(5) on this system.  See
# /etc/netplan for current configuration.
# To re-enable ifupdown on this system, you can run:
#    sudo apt install ifupdown

```

解决方案

```
root@(none):/# ifconfig
root@(none):/# ifconfig -a
eth0: flags=4098<BROADCAST,MULTICAST>  mtu 1500
        ether 52:54:00:12:34:56  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
        device interrupt 22  memory 0xfeb80000-feba0000  

lo: flags=8<LOOPBACK>  mtu 65536
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

sit0: flags=128<NOARP>  mtu 1480
        sit  txqueuelen 1000  (IPv6-in-IPv4)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

root@(none):/# 
root@(none):/# ifconfig eth0 up
[   98.065056] ifconfig (86) used greatest stack depth: 14376 bytes left
root@(none):/# [  100.739767] e1000e 0000:00:02.0 eth0: NIC Link is Up 1000 Mbps Full Duplex, Flow Control: Rx/Tx
[  100.748222] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fec0::5054:ff:fe12:3456  prefixlen 64  scopeid 0x40<site>
        inet6 fe80::5054:ff:fe12:3456  prefixlen 64  scopeid 0x20<link>
        ether 52:54:00:12:34:56  txqueuelen 1000  (Ethernet)
        RX packets 3  bytes 342 (342.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 8  bytes 1274 (1.2 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
        device interrupt 22  memory 0xfeb80000-feba0000  

root@(none):/# ping 127.0.0.1
ping: connect: Network is unreachable
root@(none):/# ifconfig lo up
[  138.869611] ifconfig (89) used greatest stack depth: 14152 bytes left
root@(none):/# ping 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=33.9 ms
```



## 探究go httpsever 并发

```
func ListenAndServe(addr string, handler Handler)
-> 
func (srv *Server) ListenAndServe() 
->
func (srv *Server) Serve(l net.Listener) error
```



## 研究io uring 是否被accept阻塞

```c
   // 打开sqpoll
   par.flags |= IORING_SETUP_SQPOLL;
   
   // 在添加accept后添加另外的请求
   add_accept_request(server_socket, &client_addr, &client_addr_len);
    int ret = submit_read_request("test.txt", &ring);
```

未发送任何请求, 但是却接收到了request, 说明不是阻塞的

```
(base) ➜  05_webserver_liburing git:(master) ✗ ./web &   
[1] 72494
getting a requset    
```



## 用C语言实现的简单web程序log

```
./web & nc 127.0.0.1 8000 -v < test.txt 
[2] 120
[  154.505530] uintr_register_handler called
[  154.506194] upid addr: 0xffff8b341744e580
[  154.506843] recv: register handler task=120 flags 0 handler 402600 ret 0
[  154.507122] uintr_create_fd called
[  154.508082] recv: Alloc vector success uintrfd 4 uvec 0 for task=120
stui core: 2
[  154.509145] pin1 creating thread
[  154.509815] pin2 after create
[  154.510530] at init, the uipi_index is:-1
[  154.511200] io_sq_thread
[  154.512300] uintr_register_sender called
[  154.512708] using msr
write tt ffff8b340e20a001  core:1
[  154.514253] send: sender=122 receiver=120 UITTE entry 0 address ffff8b340e20a000 upid addr 0xffff8b341744e580
[  154.515453] static send: register sender task=122 flags 0 ret(uipi_id)=0
adding  accept
[  154.772839] pin1 fill event to cqring
[  154.772839]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff8b340e20a001  upid addr: 0xffff8b341744e580
senduipi core: 1 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
perv: 0 | id:2 not in user mode return
[  154.776799] sending self ipi
receive, cur core:2
~ ~ ~ ~init
XXXuiret 
getting a requset
adding  accept
- - - - leave
Connection to 127.0.0.1 8000 port [tcp/*] succeeded!
[  154.793767] pin1 fill event to cqring
[  154.793767]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff8b340e20a001  upid addr: 0xffff8b341744e580
senduipi core: 1 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
~ ~ ~ ~init
XXXuiret 
getting a requset
404 Not Found: public/index.html (/)
- - - - leave
[  154.799418] pin1 fill event to cqring
[  154.799418]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff8b340e20a001  upid addr: 0xffff8b341744e580
senduipi core: 1 uitte index:0  dist core: 2 ifsend: 1, nv: 236
HTTP/1.0 404 Not Found
Content-type: text/html

<html><head><receive, cur core:2
perv: 0 | id:2 not in user mode return
title>ZeroHTTPd: Not Found</title></head><body><h1>Not Found (404)</h1><p>Your client is asking for an object that was not found on this server.</p></body></html>[  164.780769] sending self ipi
receive, cur core:2
~ ~ ~ ~init
XXXuiret 
clui core: 2
exit
getting a requset
getting a requset
write tt 0  core:2
[  164.786849] pin1 fill event to cqring
[  164.786849]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff8b340e20a001  upid addr: 0xffff8b341744e580
senduipi core: 1 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
--uif zero,prev:0 | id:2 return
[  164.791381] recv: Release uintrfd for r_task 120 uvec 0
```



## 编译uring/bench 需要在liburing目录下make -C .

2022年07月24日

## 目前实现的log:

```shell
/ # ./caturing init while.sh poll caturing
[   53.135976] uintr_register_handler called
[   53.136992] upid addr: 0xffff9995bf84d1c0
[   53.138362] recv: register handler task=91 flags 0 handler 4026a0 ret 0
[   53.139308] uintr_create_fd called
[   53.139826] recv: Alloc vector success uintrfd 3 uvec 0 for task=91
stui core: 2
[   53.140792] pin1 creating thread
[   53.141409] pin2 after create
[   53.142078] at init, the uipi_index is:0
[   53.142669] io_sq_thread
[   53.143089] uintr_register_sender called
[   53.143972] using msr
write tt ffff9995413d9001  core:0
[   53.144228] send: sender=92 receiver=91 UITTE entry 0 address ffff9995413d9000 upid addr 0xffff9995bf84d1c0
[   53.145198] static send: register sender task=92 flags 0 ret(uipi_id)=0
[   53.147130] pin1 fill event to cqring
[   53.147130]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff9995413d9001  upid addr: 0xffff9995bf84d1c0
senduipi core: 0 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
perv: 0 | id:2 not in user mode return
[   53.148952] sending self ipi
receive, cur core:2
XXXuiret 
[   53.153234] pin1 fill event to cqring
[   53.153234]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff9995413d9001  upid addr: 0xffff9995bf84d1c0
senduipi core: 0 uitte index:0  dist core: 2 ifsend: 1, nv: 236
sleeping
~ ~ ~ ~init
sleeping
- - - - coreceive, cur core:2
perv: 0 | id:2 not in user mode return
mplet[   53.166967] sending self ipi
receive, cur core:2
e:1
- - - - complete:2
XXXuiret 
awake return
io_uring_wait_cqe: Success
- - - - leave
sleeping
[   53.221065] pin1 fill event to cqring
[   53.221065]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff9995413d9001  upid addr: 0xffff9995bf84d1c0
senduipi core: 0 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
perv: 0 | id:2 not in user mode return
[   53.227060] sending self ipi
receive, cur core:2
~ ~ ~ ~init
- - - - complete:3
io_uring_wait_cqe: Success
XXXuiret 
- - - - leave
sleeping
[   53.286991] pin1 fill event to cqring
[   53.286991]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff9995413d9001  upid addr: 0xffff9995bf84d1c0
senduipi core: 0 uitte index:0  dist core: 2 ifsend: 1, nv: 236
[   53.287654] sending self ipi
receive, cur core:2
XXXuiret 
do compute
do compute
~ ~ ~ ~init
- - - - complete:4
io_uring_wait_cqe: Success
- - - - leave
clui core: 2
[   53.339068] iou-sqp-91 (92) used greatest stack depth: 13848 bytes left
exit
[   53.344294] recv: Release uintrfd for r_task 91 uvec 0
write tt 0  core:2
```





## cgo 实现协程

```
root@(none):/# ./couring test.txt test.txt 
[   27.269272] uintr_register_handler called
[   27.270497] upid addr: 0xffff97efd7efd4c0
[   27.271993] recv: register handler task=99 flags 0 handler 4025c0 ret 0
[   27.273957] uintr_create_fd called
[   27.276234] recv: Alloc vector success uintrfd 3 uvec 0 for task=99
stui core: 2
[   27.281038] pin1 creating thread
[   27.282296] pin2 after create
[   27.285554] io_sq_thread
[   27.286003] at init, the uipi_index is:-1
[   27.286458] uintr_register_sender called
[   27.288312] using msr
write tt ffff97efcf317001  core:1
[   27.288668] send: sender=101 receiver=99 UITTE entry 0 address ffff97efcf317000 upid addr 0xffff97efd7efd4c0
[   27.290595] static send: register sender task=101 flags 0 ret(uipi_id)=0
sleeping
[   27.316982] pin1 fill event to cqring
[   27.316982]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff97efcf317001  upid addr: 0xffff97efd7efd4c0
senduipi core: 1 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
perv: 0 | id:2 not in user mode return
[   27.317598] sending self ipi
receive, cur core:2
~ ~ ~ ~init
XXXuiret 
sleeping
[   27.566683] pin1 fill event to cqring
[   27.566683]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff97efcf317001  upid addr: 0xffff97efd7efd4c0
senduipi core: 1 uitte index:0  dist core: 2 ifsend: 1, nv: 236
receive, cur core:2
perv: 0 | id:2 not in user mode return
completing an cqe
[   27.575349] sending self ipi
receive, cur core:2
awake return
XXXuiret 
searched: 1
searched: 2
completing an cqe
empty pointer
clui core: 2
exit
```

协程2

```
root@(none):/# [  645.224190] uintr_register_handler called
[  645.224193] upid addr: 0xffff9f32d7252380
[  645.224193] recv: register handler task=106 flags 0 handler 4025c0 ret 0
[  645.224193] uintr_create_fd called
[  645.224193] recv: Alloc vector success uintrfd 3 uvec 0 for task=106
stui core: 0
[  645.236555] pin1 creating thread
[  645.237923] pin2 after create
[  645.238975] at init, the uipi_index is:-1
[  645.242439] io_sq_thread
[  645.244602] uintr_register_sender called
[  645.246003] using msr
write tt ffff9f32cd88c001  core:1
[  645.247938] send: sender=108 receiver=106 UITTE entry 0 address ffff9f32cd88c000 upid addr 0xffff9f32d7252380
sleeping
[  645.264117] static send: register sender task=108 flags 0 ret(uipi_id)=0
[  645.267101] pin1 fill event to cqring
[  645.267101]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff9f32cd88c001  upid addr: 0xffff9f32d7252380
senduipi core: 1 uitte index:0  dist core: 0 ifsend: 1, nv: 236
receive, cur core:0
perv: 0 | id:0 not in user mode return
[  645.281874] sending self ipi
receive, cur core:0
go to handler
out hanlder
XXXuiret
~ ~ ~ ~init
searched: 1
empty pointer
completing an cqe
sleeping
[  645.477031] pin1 fill event to cqring
[  645.477031]  the uipi_index: 0
uitte index:0
uitt addr: 0xffff9f32cd88c001  upid addr: 0xffff9f32d7252380
senduipi core: 1 uitte index:0  dist core: 0 ifsend: 1, nv: 236
receive, cur core:0
go to handler
out hanlder
~ ~ ~ ~init
searched: 2
empty pointer
XXXuiret
completing an cqe
clui core: 0
exit
```





## qemu 下的结果

#define COMP 7*100000
#define SMALL 4096
#define MID   4 * 1024 * 1024
#define LARGE 40*1024*1024
#define MAX_IO 1000
#define QUEUE_DEPTH 20

```
root@(none):/# ./uintr 20 1000
[   27.887849] uintr_register_handler called
[   27.889099] upid addr: 0xffff9bc4de90b380
[   27.890595] recv: register handler task=92 flags 0 handler 402e61 ret 0
[   27.892064] uintr_create_fd called
[   27.893958] recv: Alloc vector success uintrfd 3 uvec 0 for task=92
stui core: 1
[   27.897586] pin1 creating thread
[   27.899771] pin2 after create
[   27.902262] io_sq_thread
[   27.905323] uintr_register_sender called
[   27.909808] using msr
write tt ffff9bc4cfb25001  core:0
[   27.912252] send: sender=93 receiver=92 UITTE entry 0 address ffff9bc4cfb25000 upid addr 0xffff9bc4de90b380
[   27.916678] static send: register sender task=93 flags 0 ret(uipi_id)=0
[   28.291378] pin1 fill event to cqring
[   28.291378]  the uipi_index: 0
8
[   28.379085] pin1 fill event to cqring
[   28.379085]  the uipi_index: 0
6
[   28.422352] pin1 fill event to cqring
[   28.422352]  the uipi_index: 0
perv: 0 | id:1 not in user mode return
[   28.429675] sending self ipi
6
[   28.440344] pin1 fill event to cqring
[   28.440344]  the uipi_index: 0
6
[   28.447960] pin1 fill event to cqring
[   28.447960]  the uipi_index: 0
perv: 0 | id:1 not in user mode return
[   28.453740] sending self ipi
9
[   28.799281] pin1 fill event to cqring
[   28.799281]  the uipi_index: 0
8
[   29.191861] pin1 fill event to cqring
[   29.191861]  the uipi_index: 0
8
[   29.227510] pin1 fill event to cqring
[   29.227510]  the uipi_index: 0
perv: 0 | id:1 not in user mode return
[   29.232136] sending self ipi
9
[   29.571068] pin1 fill event to cqring
[   29.571068]  the uipi_index: 0
8
[   29.931802] pin1 fill event to cqring
[   29.931802]  the uipi_index: 0
[   29.938768] sending self ipi
8
[   30.321651] pin1 fill event to cqring
[   30.321651]  the uipi_index: 0
8
[   30.363324] pin1 fill event to cqring
[   30.363324]  the uipi_index: 0
perv: 0 | id:1 not in user mode return
[   30.365070] sending self ipi
6
[   30.374173] pin1 fill event to cqring
[   30.374173]  the uipi_index: 0
[   30.375727] sending self ipi
6
[   30.384224] pin1 fill event to cqring
[   30.384224]  the uipi_index: 0
6
[   30.387049] pin1 fill event to cqring
[   30.387049]  the uipi_index: 0
[   30.388527] sending self ipi
9
[   30.398309] pin1 fill event to cqring
[   30.398309]  the uipi_index: 0
6
[   30.741958] pin1 fill event to cqring
[   30.741958]  the uipi_index: 0
8
[   31.123698] pin1 fill event to cqring
[   31.123698]  the uipi_index: 0
8
[   31.485325] pin1 fill event to cqring
[   31.485325]  the uipi_index: 0
8
[   31.521076] pin1 fill event to cqring
[   31.521076]  the uipi_index: 0
perv: 0 | id:1 not in user mode return
[   31.526215] sending self ipi
9
2 io using 417049 us
1 io using 45757 us
1 io using 43370 us
1 io using 16230 us
0 io using 7528 us
2 io using 378428 us
2 io using 393476 us
0 io using 7260 us
2 io using 369607 us
2 io using 384860 us
2 io using 363428 us
1 io using 17659 us
1 io using 9867 us
1 io using 7148 us
0 io using 6348 us
1 io using 11601 us
2 io using 372336 us
2 io using 379065 us
2 io using 363826 us
0 io using 7943 us
total Using time : 9545622 ms
write tt 0  core:1
[   37.501851] recv: Release uintrfd for r_task 92 uvec 0
[   37.508879] iou-sqp-92 (93) used greatest stack depth: 13848 bytes left
root@(none):/# 

2 io using 407146 us
1 io using 51844 us
1 io using 43075 us
1 io using 20768 us
0 io using 6802 us
2 io using 392564 us
2 io using 403705 us
0 io using 35293 us
2 io using 392040 us
2 io using 389298 us
2 io using 393554 us
1 io using 20973 us
1 io using 19435 us
1 io using 18530 us
0 io using 7589 us
1 io using 18043 us
2 io using 389370 us
2 io using 378246 us
2 io using 385116 us
0 io using 9682 us
total Using time : 9512513 ms
```





```
uring 20 1000
2 io using 403074 us
1 io using 59458 us
1 io using 45190 us
1 io using 14353 us
0 io using 25167 us
2 io using 362924 us
2 io using 389373 us
0 io using 14083 us
2 io using 383974 us
2 io using 391357 us
2 io using 418377 us
1 io using 20283 us
1 io using 14500 us
1 io using 26229 us
0 io using 16352 us
1 io using 24589 us
2 io using 366634 us
2 io using 367055 us
2 io using 372494 us
0 io using 8015 us
total Using time : 9174802 ms

2 io using 400956 us
1 io using 52495 us
1 io using 47371 us
1 io using 13138 us
0 io using 27564 us
2 io using 394466 us
2 io using 399073 us
0 io using 19064 us
2 io using 378227 us
2 io using 370691 us
2 io using 369126 us
1 io using 32497 us
1 io using 20699 us
1 io using 27596 us
0 io using 22355 us
1 io using 18681 us
2 io using 362045 us
2 io using 378490 us
2 io using 378110 us
0 io using 10006 us
total Using time : 9133310 ms
```





```
normal 20 1000
compute  Using time : 8478665 us
2 io using 249248 us
1 io using 25851 us
1 io using 23586 us
1 io using 3557 us
0 io using 713 us
2 io using 239762 us
2 io using 235430 us
0 io using 751 us
2 io using 248824 us
2 io using 233971 us
2 io using 234957 us
1 io using 7234 us
1 io using 3030 us
1 io using 2977 us
0 io using 313 us
1 io using 2927 us
2 io using 239469 us
2 io using 240059 us
2 io using 235923 us
0 io using 944 us
total Using time : 10712346 ms
```





### uintr 50 1000

```
uintr 50 1000
2 io using 393261 us
1 io using 47542 us
1 io using 40395 us
1 io using 13555 us
0 io using 7749 us
2 io using 369141 us
2 io using 405476 us
0 io using 7414 us
2 io using 360612 us
2 io using 367201 us
2 io using 368151 us
1 io using 20716 us
1 io using 11084 us
1 io using 9919 us
0 io using 7945 us
1 io using 7486 us
2 io using 365073 us
2 io using 381277 us
2 io using 368767 us
0 io using 3925 us
0 io using 8352 us
2 io using 370211 us
0 io using 3588 us
0 io using 6289 us
0 io using 5306 us
0 io using 4471 us
2 io using 372889 us
1 io using 22000 us
1 io using 11308 us
2 io using 367698 us
2 io using 371042 us
2 io using 360504 us
2 io using 368354 us
1 io using 14310 us
0 io using 5776 us
2 io using 377908 us
0 io using 8457 us
2 io using 371335 us
1 io using 17417 us
2 io using 367029 us
0 io using 5205 us
0 io using 4652 us
1 io using 19010 us
1 io using 11278 us
2 io using 364072 us
1 io using 18384 us
2 io using 367034 us
2 io using 372601 us
1 io using 13526 us
2 io using 361025 us
total Using time : 12166582 ms
```



### uintr 20 1000 无内核输出

```
9
2 io using 412074 us
1 io using 45841 us
1 io using 38260 us
1 io using 11163 us
0 io using 2320 us
2 io using 384635 us
2 io using 392474 us
0 io using 1443 us
2 io using 377594 us
2 io using 382970 us
2 io using 366476 us
1 io using 13192 us
1 io using 6048 us
1 io using 6491 us
0 io using 616 us
1 io using 6388 us
2 io using 367265 us
2 io using 369901 us
2 io using 368704 us
0 io using 20899 us
total Using time : 9076361 ms
```

### uintr 50 1000 无内核输出

```
2 io using 399069 us
1 io using 40811 us
1 io using 33824 us
1 io using 10401 us
0 io using 858 us
2 io using 348738 us
2 io using 333208 us
0 io using 5060 us
2 io using 323213 us
2 io using 320816 us
2 io using 328574 us
1 io using 10493 us
1 io using 4883 us
1 io using 5148 us
0 io using 1178 us
1 io using 5130 us
2 io using 331201 us
2 io using 318810 us
2 io using 321129 us
0 io using 1395 us
0 io using 562 us
2 io using 320423 us
0 io using 1538 us
0 io using 726 us
0 io using 519 us
0 io using 566 us
2 io using 319548 us
1 io using 11351 us
1 io using 4613 us
2 io using 318931 us
2 io using 317593 us
2 io using 321561 us
2 io using 317999 us
1 io using 10280 us
0 io using 809 us
2 io using 316777 us
0 io using 1441 us
2 io using 336539 us
1 io using 10462 us
2 io using 318346 us
0 io using 1504 us
0 io using 750 us
1 io using 9947 us
1 io using 4867 us
2 io using 318284 us
1 io using 11137 us
2 io using 322510 us
2 io using 327101 us
1 io using 10559 us
2 io using 332879 us
total Using time : 10350998 ms
write tt 0  core:1
```



### uring 50 1000 无内核输出

```
2 io using 344296 us
1 io using 37980 us
1 io using 54533 us
1 io using 17979 us
0 io using 9380 us
2 io using 323819 us
2 io using 349629 us
0 io using 19829 us
2 io using 328777 us
2 io using 320477 us
2 io using 338435 us
1 io using 18518 us
1 io using 15881 us
1 io using 9081 us
0 io using 5445 us
1 io using 17400 us
2 io using 333728 us
2 io using 327776 us
2 io using 327501 us
0 io using 14028 us
0 io using 2965 us
2 io using 334489 us
0 io using 5704 us
0 io using 21079 us
0 io using 15657 us
0 io using 21502 us
2 io using 326677 us
1 io using 16019 us
1 io using 8507 us
2 io using 322291 us
2 io using 333257 us
2 io using 320096 us
2 io using 321189 us
1 io using 17362 us
0 io using 19786 us
2 io using 323077 us
0 io using 21916 us
2 io using 333206 us
1 io using 20975 us
2 io using 328570 us
0 io using 18443 us
0 io using 17544 us
1 io using 11267 us
1 io using 17802 us
2 io using 336491 us
1 io using 11648 us
2 io using 326644 us
2 io using 322943 us
1 io using 13568 us
2 io using 324057 us
total Using time : 10466807 ms
```





### uring 50 1000

```
2 io using 393594 us
1 io using 67218 us
1 io using 44502 us
1 io using 35699 us
0 io using 10971 us
2 io using 399705 us
2 io using 376598 us
0 io using 24658 us
2 io using 362670 us
2 io using 377227 us
2 io using 373669 us
1 io using 17026 us
1 io using 20160 us
1 io using 13933 us
0 io using 6278 us
1 io using 22799 us
2 io using 383685 us
2 io using 377312 us
2 io using 377406 us
0 io using 26479 us
0 io using 9576 us
2 io using 379738 us
0 io using 25745 us
0 io using 23922 us
0 io using 12026 us
0 io using 23971 us
2 io using 364808 us
1 io using 32893 us
1 io using 21798 us
2 io using 376451 us
2 io using 371220 us
2 io using 376340 us
2 io using 368942 us
1 io using 31156 us
0 io using 25003 us
2 io using 375068 us
0 io using 13274 us
2 io using 374143 us
1 io using 19612 us
2 io using 387877 us
0 io using 17036 us
0 io using 15853 us
1 io using 17302 us
1 io using 19604 us
2 io using 379353 us
1 io using 27046 us
2 io using 372683 us
2 io using 382054 us
1 io using 26059 us
2 io using 367670 us
total Using time : 12037190 ms
```







### uring 200 100, 无内核输出

```
2 io using 353230 us
1 io using 58867 us
1 io using 36336 us
1 io using 24406 us
0 io using 18744 us
2 io using 364610 us
2 io using 382329 us
0 io using 9472 us
2 io using 382154 us
2 io using 385780 us
2 io using 400903 us
1 io using 12560 us
1 io using 6979 us
1 io using 5716 us
0 io using 1136 us
1 io using 5749 us
2 io using 403386 us
2 io using 379008 us
2 io using 397361 us
0 io using 2414 us
0 io using 956 us
2 io using 393021 us
0 io using 1963 us
0 io using 995 us
0 io using 904 us
0 io using 664 us
2 io using 392013 us
1 io using 13448 us
1 io using 5678 us
2 io using 389431 us
2 io using 383930 us
2 io using 388316 us
2 io using 392157 us
1 io using 14085 us
0 io using 793 us
2 io using 399479 us
0 io using 1355 us
2 io using 388122 us
1 io using 12964 us
2 io using 380679 us
0 io using 2324 us
0 io using 1000 us
1 io using 10552 us
1 io using 4866 us
2 io using 406671 us
1 io using 11726 us
2 io using 389584 us
2 io using 386502 us
1 io using 11693 us
2 io using 383901 us
2 io using 386912 us
2 io using 384003 us
0 io using 1990 us
0 io using 527 us
0 io using 857 us
0 io using 716 us
1 io using 12316 us
2 io using 393123 us
2 io using 472419 us
0 io using 1760 us
0 io using 1013 us
1 io using 11781 us
2 io using 392136 us
2 io using 401186 us
2 io using 388206 us
1 io using 13792 us
2 io using 394139 us
2 io using 391699 us
1 io using 13201 us
0 io using 822 us
2 io using 380866 us
1 io using 13683 us
2 io using 386485 us
0 io using 1964 us
0 io using 558 us
2 io using 381539 us
2 io using 378871 us
0 io using 1882 us
1 io using 11974 us
1 io using 5168 us
0 io using 910 us
1 io using 5079 us
1 io using 5520 us
0 io using 849 us
2 io using 389927 us
2 io using 386292 us
1 io using 11759 us
1 io using 7709 us
2 io using 387254 us
0 io using 2191 us
1 io using 11021 us
0 io using 1121 us
2 io using 387643 us
2 io using 385071 us
2 io using 397002 us
2 io using 388235 us
0 io using 1838 us
2 io using 396012 us
2 io using 392184 us
1 io using 38649 us
1 io using 17864 us
2 io using 420914 us
1 io using 12742 us
0 io using 1188 us
1 io using 5188 us
1 io using 5145 us
0 io using 1092 us
1 io using 5468 us
2 io using 387923 us
1 io using 12312 us
0 io using 1092 us
0 io using 794 us
2 io using 390263 us
2 io using 377399 us
1 io using 12513 us
1 io using 6845 us
2 io using 382914 us
2 io using 385821 us
0 io using 1910 us
1 io using 10982 us
1 io using 5263 us
2 io using 385010 us
1 io using 11658 us
0 io using 1181 us
2 io using 381019 us
1 io using 12129 us
0 io using 794 us
2 io using 404988 us
1 io using 13092 us
0 io using 956 us
1 io using 5613 us
2 io using 383164 us
0 io using 2137 us
2 io using 380587 us
0 io using 2047 us
1 io using 11582 us
1 io using 5361 us
0 io using 993 us
0 io using 551 us
2 io using 393559 us
2 io using 376803 us
1 io using 11545 us
2 io using 376548 us
2 io using 388292 us
0 io using 1595 us
2 io using 389963 us
1 io using 12625 us
2 io using 390574 us
2 io using 382743 us
2 io using 394437 us
1 io using 11799 us
0 io using 1821 us
2 io using 414190 us
2 io using 393056 us
1 io using 12274 us
1 io using 6032 us
1 io using 5954 us
2 io using 402669 us
1 io using 12321 us
0 io using 1484 us
2 io using 387819 us
0 io using 1678 us
0 io using 953 us
0 io using 756 us
0 io using 785 us
2 io using 379801 us
2 io using 386599 us
2 io using 390561 us
0 io using 1964 us
0 io using 805 us
1 io using 12932 us
0 io using 1341 us
1 io using 5540 us
2 io using 387190 us
0 io using 2005 us
2 io using 371903 us
1 io using 13140 us
1 io using 6173 us
2 io using 391658 us
1 io using 12166 us
1 io using 5173 us
0 io using 1166 us
2 io using 386597 us
0 io using 2974 us
1 io using 11822 us
1 io using 5652 us
2 io using 377368 us
2 io using 395906 us
1 io using 12631 us
1 io using 6242 us
2 io using 383086 us
1 io using 12176 us
2 io using 401276 us
1 io using 12147 us
2 io using 377467 us
0 io using 1763 us
0 io using 380 us
2 io using 387031 us
2 io using 392955 us
0 io using 1998 us
total Using time : 32387407 ms
```





### normal 50 1000

```
compute  Using time : 8641100 us
2 io using 251435 us
1 io using 25615 us
1 io using 23669 us
1 io using 4018 us
0 io using 367 us
2 io using 241515 us
2 io using 239066 us
0 io using 749 us
2 io using 241121 us
2 io using 238368 us
2 io using 237673 us
1 io using 7456 us
1 io using 3050 us
1 io using 3136 us
0 io using 263 us
1 io using 3056 us
2 io using 250390 us
2 io using 238888 us
2 io using 237666 us
0 io using 935 us
0 io using 229 us
2 io using 239219 us
0 io using 696 us
0 io using 530 us
0 io using 229 us
0 io using 207 us
2 io using 241557 us
1 io using 7335 us
1 io using 3182 us
2 io using 242449 us
2 io using 238265 us
2 io using 235114 us
2 io using 236862 us
1 io using 7551 us
0 io using 344 us
2 io using 242769 us
0 io using 989 us
2 io using 240406 us
1 io using 7692 us
2 io using 238795 us
0 io using 649 us
0 io using 314 us
1 io using 7055 us
1 io using 2969 us
2 io using 242109 us
1 io using 7238 us
2 io using 241828 us
2 io using 238309 us
1 io using 7497 us
2 io using 241186 us
total Using time : 14067941 ms
root@(none):/# 
```

###  

### normal 20 1000

```
compute  Using time : 7045121 us
2 io using 256031 us
1 io using 25794 us
1 io using 24824 us
1 io using 6585 us
0 io using 660 us
2 io using 264532 us
2 io using 245739 us
0 io using 724 us
2 io using 257868 us
2 io using 243352 us
2 io using 243532 us
1 io using 7255 us
1 io using 6628 us
1 io using 6416 us
0 io using 270 us
1 io using 6454 us
2 io using 248200 us
2 io using 245037 us
2 io using 249652 us
0 io using 1022 us
total Using time : 9389484 ms
```





本机下的结果

```
```





## 参考

1. go 调度 https://www.cnblogs.com/sunsky303/p/9705727.html
2. rust 异步 https://huangjj27.github.io/async-book/01_getting_started/04_async_await_primer.html
3. 并发简介 https://segmentfault.com/a/1190000023885742
4. c语言编写的简单服务器
5. go 嵌套C http://www.codebaoku.com/it-go/it-go-61412.html
6. io_uring 介绍 https://zhuanlan.zhihu.com/p/62682475
7. accept 系统调用 https://blog.csdn.net/u010039418/article/details/80628490
8. http https://www.cnblogs.com/biyeymyhjob/archive/2012/07/28/2612910.html
9. listen and accept http://c.biancheng.net/cpp/html/3036.html
10. cpp 协程, 包括bench测试 https://github.com/yunwei37/co-uring-WebServer/blob/master/document/part1.md
11. go 写的web程序 https://github.com/jimmahoney/golang-webserver/blob/master/webserver.go
12. rust liburing https://github.com/sitano/liburing
13. cgo 编程 https://chai2010.cn/advanced-go-programming-book/ch2-cgo/ch2-01-hello-cgo.html
14. go 中静态链接
